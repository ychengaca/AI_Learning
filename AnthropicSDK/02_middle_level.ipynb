{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ”¥ Anthropic SDK - Middle Level\n",
        "\n",
        "## Intermediate Concepts for the Anthropic Python SDK\n",
        "\n",
        "This notebook builds on the basics and introduces more powerful features.\n",
        "\n",
        "### What You'll Learn:\n",
        "- Streaming responses for real-time output\n",
        "- Temperature and other generation parameters\n",
        "- Working with images (vision capabilities)\n",
        "- Counting tokens before sending requests\n",
        "- Building a conversation manager class\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup\n",
        "\n",
        "Import our configuration and create the client."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import anthropic\n",
        "from config import MODEL, ANTHROPIC_API_KEY, validate_api_key, DEFAULT_MAX_TOKENS\n",
        "\n",
        "# Validate and create client\n",
        "validate_api_key()\n",
        "client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)\n",
        "\n",
        "print(f\"Model: {MODEL}\")\n",
        "print(\"Ready for intermediate concepts!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Streaming Responses\n",
        "\n",
        "Streaming allows you to receive Claude's response in real-time, token by token. This is essential for:\n",
        "- Better user experience (users see output immediately)\n",
        "- Long responses that would otherwise timeout\n",
        "- Interactive applications"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Basic streaming example\n",
        "print(\"Streaming response:\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "with client.messages.stream(\n",
        "    model=MODEL,\n",
        "    max_tokens=500,\n",
        "    messages=[{\"role\": \"user\", \"content\": \"Write a short poem about coding.\"}]\n",
        ") as stream:\n",
        "    for text in stream.text_stream:\n",
        "        print(text, end=\"\", flush=True)\n",
        "\n",
        "print(\"\\n\" + \"-\" * 50)\n",
        "print(\"Stream complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Streaming with event handling for more control\n",
        "print(\"Streaming with events:\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "collected_text = []\n",
        "\n",
        "with client.messages.stream(\n",
        "    model=MODEL,\n",
        "    max_tokens=300,\n",
        "    messages=[{\"role\": \"user\", \"content\": \"Explain what an API is in 2 sentences.\"}]\n",
        ") as stream:\n",
        "    for text in stream.text_stream:\n",
        "        collected_text.append(text)\n",
        "        print(text, end=\"\", flush=True)\n",
        "\n",
        "# Get the final message with usage stats\n",
        "final_message = stream.get_final_message()\n",
        "\n",
        "print(\"\\n\" + \"-\" * 50)\n",
        "print(f\"\\nTotal characters streamed: {len(''.join(collected_text))}\")\n",
        "print(f\"Input tokens: {final_message.usage.input_tokens}\")\n",
        "print(f\"Output tokens: {final_message.usage.output_tokens}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Temperature and Generation Parameters\n",
        "\n",
        "Temperature controls the randomness/creativity of responses:\n",
        "- `0.0` = Deterministic, focused responses\n",
        "- `1.0` = Default, balanced creativity\n",
        "- Higher = More creative/random (max varies by model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare different temperatures\n",
        "prompt = \"Give me a creative name for a coffee shop.\"\n",
        "\n",
        "print(\"Temperature Comparison\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for temp in [0.0, 0.5, 1.0]:\n",
        "    print(f\"\\nTemperature: {temp}\")\n",
        "    print(\"-\" * 40)\n",
        "    \n",
        "    # Run 3 times to show variability\n",
        "    for i in range(3):\n",
        "        response = client.messages.create(\n",
        "            model=MODEL,\n",
        "            max_tokens=50,\n",
        "            temperature=temp,\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "        )\n",
        "        print(f\"  {i+1}. {response.content[0].text.strip()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Top-p (nucleus sampling) - another way to control randomness\n",
        "# Lower top_p = more focused, higher = more diverse\n",
        "response = client.messages.create(\n",
        "    model=MODEL,\n",
        "    max_tokens=100,\n",
        "    temperature=1.0,\n",
        "    top_p=0.9,  # Only consider tokens in the top 90% probability mass\n",
        "    messages=[{\"role\": \"user\", \"content\": \"Describe a sunset in one sentence.\"}]\n",
        ")\n",
        "\n",
        "print(\"Using top_p=0.9:\")\n",
        "print(response.content[0].text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Stop Sequences\n",
        "\n",
        "Stop sequences tell Claude when to stop generating. Useful for structured outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Using stop sequences\n",
        "response = client.messages.create(\n",
        "    model=MODEL,\n",
        "    max_tokens=200,\n",
        "    stop_sequences=[\"END\", \"---\"],  # Stop when Claude outputs these\n",
        "    messages=[{\n",
        "        \"role\": \"user\", \n",
        "        \"content\": \"List 3 programming languages, then write END, then list 3 more.\"\n",
        "    }]\n",
        ")\n",
        "\n",
        "print(\"Response (stopped at 'END'):\")\n",
        "print(response.content[0].text)\n",
        "print(f\"\\nStop reason: {response.stop_reason}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Working with Images (Vision)\n",
        "\n",
        "Claude can analyze images! You can send images as base64 or URLs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import base64\n",
        "import httpx\n",
        "\n",
        "# Method 1: Image from URL\n",
        "image_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/c/c3/Python-logo-notext.svg/200px-Python-logo-notext.svg.png\"\n",
        "\n",
        "# Fetch and encode the image\n",
        "image_data = base64.standard_b64encode(httpx.get(image_url).content).decode(\"utf-8\")\n",
        "\n",
        "response = client.messages.create(\n",
        "    model=MODEL,\n",
        "    max_tokens=300,\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\n",
        "                    \"type\": \"image\",\n",
        "                    \"source\": {\n",
        "                        \"type\": \"base64\",\n",
        "                        \"media_type\": \"image/png\",\n",
        "                        \"data\": image_data,\n",
        "                    },\n",
        "                },\n",
        "                {\n",
        "                    \"type\": \"text\",\n",
        "                    \"text\": \"What is this logo? Describe it briefly.\"\n",
        "                }\n",
        "            ],\n",
        "        }\n",
        "    ],\n",
        ")\n",
        "\n",
        "print(\"Image Analysis:\")\n",
        "print(\"-\" * 50)\n",
        "print(response.content[0].text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Helper function for image analysis\n",
        "def analyze_image_from_url(image_url, question, media_type=\"image/png\"):\n",
        "    \"\"\"Analyze an image from a URL.\"\"\"\n",
        "    image_data = base64.standard_b64encode(httpx.get(image_url).content).decode(\"utf-8\")\n",
        "    \n",
        "    response = client.messages.create(\n",
        "        model=MODEL,\n",
        "        max_tokens=500,\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\n",
        "                        \"type\": \"image\",\n",
        "                        \"source\": {\n",
        "                            \"type\": \"base64\",\n",
        "                            \"media_type\": media_type,\n",
        "                            \"data\": image_data,\n",
        "                        },\n",
        "                    },\n",
        "                    {\"type\": \"text\", \"text\": question}\n",
        "                ],\n",
        "            }\n",
        "        ],\n",
        "    )\n",
        "    return response.content[0].text\n",
        "\n",
        "# Example usage\n",
        "result = analyze_image_from_url(\n",
        "    \"https://upload.wikimedia.org/wikipedia/commons/thumb/4/4c/Typescript_logo_2020.svg/200px-Typescript_logo_2020.svg.png\",\n",
        "    \"What programming language does this logo represent?\"\n",
        ")\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Token Counting\n",
        "\n",
        "Count tokens before sending requests to estimate costs and stay within limits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Count tokens using the API\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"What is the meaning of life, the universe, and everything?\"}\n",
        "]\n",
        "\n",
        "# Count tokens before sending\n",
        "token_count = client.messages.count_tokens(\n",
        "    model=MODEL,\n",
        "    messages=messages\n",
        ")\n",
        "\n",
        "print(f\"Input tokens: {token_count.input_tokens}\")\n",
        "\n",
        "# Now make the actual request\n",
        "response = client.messages.create(\n",
        "    model=MODEL,\n",
        "    max_tokens=100,\n",
        "    messages=messages\n",
        ")\n",
        "\n",
        "print(f\"Actual input tokens used: {response.usage.input_tokens}\")\n",
        "print(f\"Output tokens used: {response.usage.output_tokens}\")\n",
        "print(f\"\\nResponse: {response.content[0].text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Building a Conversation Manager\n",
        "\n",
        "Let's create a reusable class to manage conversations with Claude."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ConversationManager:\n",
        "    \"\"\"Manage multi-turn conversations with Claude.\"\"\"\n",
        "    \n",
        "    def __init__(self, client, model=MODEL, system=None, max_tokens=DEFAULT_MAX_TOKENS):\n",
        "        self.client = client\n",
        "        self.model = model\n",
        "        self.system = system\n",
        "        self.max_tokens = max_tokens\n",
        "        self.messages = []\n",
        "        self.total_input_tokens = 0\n",
        "        self.total_output_tokens = 0\n",
        "    \n",
        "    def chat(self, user_message, stream=False):\n",
        "        \"\"\"Send a message and get a response.\"\"\"\n",
        "        # Add user message\n",
        "        self.messages.append({\"role\": \"user\", \"content\": user_message})\n",
        "        \n",
        "        # Build request kwargs\n",
        "        kwargs = {\n",
        "            \"model\": self.model,\n",
        "            \"max_tokens\": self.max_tokens,\n",
        "            \"messages\": self.messages\n",
        "        }\n",
        "        if self.system:\n",
        "            kwargs[\"system\"] = self.system\n",
        "        \n",
        "        if stream:\n",
        "            return self._stream_response(kwargs)\n",
        "        else:\n",
        "            return self._get_response(kwargs)\n",
        "    \n",
        "    def _get_response(self, kwargs):\n",
        "        \"\"\"Get a non-streaming response.\"\"\"\n",
        "        response = self.client.messages.create(**kwargs)\n",
        "        \n",
        "        # Track tokens\n",
        "        self.total_input_tokens += response.usage.input_tokens\n",
        "        self.total_output_tokens += response.usage.output_tokens\n",
        "        \n",
        "        # Add assistant response to history\n",
        "        assistant_message = response.content[0].text\n",
        "        self.messages.append({\"role\": \"assistant\", \"content\": assistant_message})\n",
        "        \n",
        "        return assistant_message\n",
        "    \n",
        "    def _stream_response(self, kwargs):\n",
        "        \"\"\"Get a streaming response.\"\"\"\n",
        "        collected_text = []\n",
        "        \n",
        "        with self.client.messages.stream(**kwargs) as stream:\n",
        "            for text in stream.text_stream:\n",
        "                collected_text.append(text)\n",
        "                print(text, end=\"\", flush=True)\n",
        "            \n",
        "            final_message = stream.get_final_message()\n",
        "            self.total_input_tokens += final_message.usage.input_tokens\n",
        "            self.total_output_tokens += final_message.usage.output_tokens\n",
        "        \n",
        "        assistant_message = \"\".join(collected_text)\n",
        "        self.messages.append({\"role\": \"assistant\", \"content\": assistant_message})\n",
        "        print()  # New line after streaming\n",
        "        \n",
        "        return assistant_message\n",
        "    \n",
        "    def get_stats(self):\n",
        "        \"\"\"Get conversation statistics.\"\"\"\n",
        "        return {\n",
        "            \"message_count\": len(self.messages),\n",
        "            \"total_input_tokens\": self.total_input_tokens,\n",
        "            \"total_output_tokens\": self.total_output_tokens,\n",
        "            \"total_tokens\": self.total_input_tokens + self.total_output_tokens\n",
        "        }\n",
        "    \n",
        "    def clear(self):\n",
        "        \"\"\"Clear conversation history.\"\"\"\n",
        "        self.messages = []\n",
        "        self.total_input_tokens = 0\n",
        "        self.total_output_tokens = 0\n",
        "\n",
        "print(\"ConversationManager class defined!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use the ConversationManager\n",
        "conv = ConversationManager(\n",
        "    client, \n",
        "    system=\"You are a helpful Python tutor. Keep responses concise.\"\n",
        ")\n",
        "\n",
        "# Have a conversation\n",
        "print(\"Message 1:\")\n",
        "print(conv.chat(\"What is a list in Python?\"))\n",
        "print(\"\\n\" + \"=\" * 50 + \"\\n\")\n",
        "\n",
        "print(\"Message 2:\")\n",
        "print(conv.chat(\"How do I add items to it?\"))\n",
        "print(\"\\n\" + \"=\" * 50 + \"\\n\")\n",
        "\n",
        "print(\"Message 3:\")\n",
        "print(conv.chat(\"What did we discuss first?\"))\n",
        "print(\"\\n\" + \"=\" * 50 + \"\\n\")\n",
        "\n",
        "# Check stats\n",
        "print(\"Conversation Statistics:\")\n",
        "print(conv.get_stats())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Practice Exercises"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exercise 1: Create a streaming response that writes a haiku\n",
        "# Your code here:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exercise 2: Compare temperature=0 vs temperature=1 for generating a product tagline\n",
        "# Your code here:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exercise 3: Extend ConversationManager to support saving/loading conversations\n",
        "# Your code here:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "In this notebook, you learned:\n",
        "\n",
        "1. **Streaming** - Real-time token-by-token responses\n",
        "2. **Temperature** - Controlling creativity and randomness\n",
        "3. **Top-p sampling** - Alternative randomness control\n",
        "4. **Stop sequences** - Custom stopping conditions\n",
        "5. **Vision** - Analyzing images with Claude\n",
        "6. **Token counting** - Estimating costs before requests\n",
        "7. **Conversation management** - Building reusable conversation classes\n",
        "\n",
        "---\n",
        "\n",
        "**Next:** Move on to `03_advanced_level.ipynb` to learn about tool use, JSON mode, and advanced patterns!"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
