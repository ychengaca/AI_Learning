{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸŽ¯ Anthropic SDK - Specialty Level\n",
        "\n",
        "## Advanced Specialized Topics\n",
        "\n",
        "This notebook covers specialized and cutting-edge features of the Anthropic SDK for production applications.\n",
        "\n",
        "### What You'll Learn:\n",
        "- Extended Thinking (Chain of Thought reasoning)\n",
        "- Batch Processing for high-volume operations\n",
        "- PDF Document Processing\n",
        "- Citations and Source Attribution\n",
        "- Building AI Agents with complex workflows\n",
        "- Production patterns and best practices\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import anthropic\n",
        "import json\n",
        "import base64\n",
        "import httpx\n",
        "import asyncio\n",
        "import time\n",
        "from config import MODEL, ANTHROPIC_API_KEY, validate_api_key, DEFAULT_MAX_TOKENS\n",
        "\n",
        "validate_api_key()\n",
        "client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)\n",
        "async_client = anthropic.AsyncAnthropic(api_key=ANTHROPIC_API_KEY)\n",
        "\n",
        "print(f\"Model: {MODEL}\")\n",
        "print(\"Ready for specialty topics!\")\n",
        "\n",
        "# Note: Some features require specific models\n",
        "# Extended Thinking requires Claude 3.5 Sonnet or Claude 3 Opus\n",
        "THINKING_MODEL = \"claude-sonnet-4-20250514\"  # For extended thinking examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Extended Thinking (Chain of Thought)\n",
        "\n",
        "Extended Thinking allows Claude to \"think\" through complex problems step-by-step before providing an answer. This is powerful for:\n",
        "- Complex reasoning tasks\n",
        "- Math problems\n",
        "- Code analysis\n",
        "- Multi-step problem solving\n",
        "\n",
        "**Note:** Extended thinking requires Claude 3.5 Sonnet or Claude 3 Opus models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extended Thinking Example\n",
        "# This feature allows Claude to reason through complex problems\n",
        "\n",
        "def extended_thinking_example(question, budget_tokens=5000):\n",
        "    \"\"\"\n",
        "    Use extended thinking for complex reasoning tasks.\n",
        "    \n",
        "    Args:\n",
        "        question: The complex question to analyze\n",
        "        budget_tokens: Maximum tokens for thinking (1024-100000)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = client.messages.create(\n",
        "            model=THINKING_MODEL,\n",
        "            max_tokens=16000,\n",
        "            thinking={\n",
        "                \"type\": \"enabled\",\n",
        "                \"budget_tokens\": budget_tokens  # Tokens allocated for thinking\n",
        "            },\n",
        "            messages=[\n",
        "                {\"role\": \"user\", \"content\": question}\n",
        "            ]\n",
        "        )\n",
        "        \n",
        "        # Process the response - it contains both thinking and text blocks\n",
        "        thinking_content = \"\"\n",
        "        response_text = \"\"\n",
        "        \n",
        "        for block in response.content:\n",
        "            if block.type == \"thinking\":\n",
        "                thinking_content = block.thinking\n",
        "            elif block.type == \"text\":\n",
        "                response_text = block.text\n",
        "        \n",
        "        return {\n",
        "            \"thinking\": thinking_content,\n",
        "            \"response\": response_text,\n",
        "            \"usage\": {\n",
        "                \"input_tokens\": response.usage.input_tokens,\n",
        "                \"output_tokens\": response.usage.output_tokens\n",
        "            }\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "# Test with a complex reasoning problem\n",
        "result = extended_thinking_example(\n",
        "    \"A farmer has 17 sheep. All but 9 run away. How many sheep does the farmer have left? Explain your reasoning step by step.\"\n",
        ")\n",
        "\n",
        "if \"error\" not in result:\n",
        "    print(\"ðŸ§  Claude's Thinking Process:\")\n",
        "    print(\"=\" * 60)\n",
        "    print(result[\"thinking\"][:1000] + \"...\" if len(result.get(\"thinking\", \"\")) > 1000 else result.get(\"thinking\", \"\"))\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"\\nðŸ“ Final Answer:\")\n",
        "    print(result[\"response\"])\n",
        "else:\n",
        "    print(f\"Note: Extended thinking requires a supported model. Error: {result['error']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Streaming with Extended Thinking\n",
        "# You can also stream responses with thinking enabled\n",
        "\n",
        "async def stream_with_thinking(question, budget_tokens=5000):\n",
        "    \"\"\"Stream a response with extended thinking.\"\"\"\n",
        "    print(\"ðŸ§  Streaming thinking and response...\\n\")\n",
        "    \n",
        "    thinking_text = []\n",
        "    response_text = []\n",
        "    current_block_type = None\n",
        "    \n",
        "    try:\n",
        "        async with async_client.messages.stream(\n",
        "            model=THINKING_MODEL,\n",
        "            max_tokens=8000,\n",
        "            thinking={\n",
        "                \"type\": \"enabled\",\n",
        "                \"budget_tokens\": budget_tokens\n",
        "            },\n",
        "            messages=[{\"role\": \"user\", \"content\": question}]\n",
        "        ) as stream:\n",
        "            async for event in stream:\n",
        "                # Handle different event types\n",
        "                if hasattr(event, 'type'):\n",
        "                    if event.type == 'content_block_start':\n",
        "                        if hasattr(event, 'content_block'):\n",
        "                            current_block_type = event.content_block.type\n",
        "                            if current_block_type == \"thinking\":\n",
        "                                print(\"ðŸ’­ Thinking:\", end=\" \")\n",
        "                            elif current_block_type == \"text\":\n",
        "                                print(\"\\n\\nðŸ“ Response:\", end=\" \")\n",
        "                    \n",
        "                    elif event.type == 'content_block_delta':\n",
        "                        if hasattr(event, 'delta'):\n",
        "                            if hasattr(event.delta, 'thinking'):\n",
        "                                print(event.delta.thinking, end=\"\", flush=True)\n",
        "                                thinking_text.append(event.delta.thinking)\n",
        "                            elif hasattr(event.delta, 'text'):\n",
        "                                print(event.delta.text, end=\"\", flush=True)\n",
        "                                response_text.append(event.delta.text)\n",
        "        \n",
        "        print(\"\\n\\nâœ… Stream complete!\")\n",
        "        return {\n",
        "            \"thinking\": \"\".join(thinking_text),\n",
        "            \"response\": \"\".join(response_text)\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"\\nNote: Extended thinking streaming requires a supported model. Error: {e}\")\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "# Run the streaming example\n",
        "result = await stream_with_thinking(\n",
        "    \"What is 15% of 240? Show your calculation.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Batch Processing\n",
        "\n",
        "Batch processing allows you to send multiple requests at once for high-volume operations. This is ideal for:\n",
        "- Processing large datasets\n",
        "- Bulk content generation\n",
        "- Cost optimization (batch requests are typically cheaper)\n",
        "- Background processing jobs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Batch Processing Example\n",
        "# Create multiple requests to be processed as a batch\n",
        "\n",
        "def create_batch_requests(prompts):\n",
        "    \"\"\"\n",
        "    Create batch requests from a list of prompts.\n",
        "    \n",
        "    Args:\n",
        "        prompts: List of (custom_id, prompt) tuples\n",
        "    \n",
        "    Returns:\n",
        "        List of batch request objects\n",
        "    \"\"\"\n",
        "    requests = []\n",
        "    for custom_id, prompt in prompts:\n",
        "        requests.append({\n",
        "            \"custom_id\": custom_id,\n",
        "            \"params\": {\n",
        "                \"model\": MODEL,\n",
        "                \"max_tokens\": 256,\n",
        "                \"messages\": [\n",
        "                    {\"role\": \"user\", \"content\": prompt}\n",
        "                ]\n",
        "            }\n",
        "        })\n",
        "    return requests\n",
        "\n",
        "# Example prompts for batch processing\n",
        "prompts = [\n",
        "    (\"summary-1\", \"Summarize the concept of machine learning in one sentence.\"),\n",
        "    (\"summary-2\", \"Summarize the concept of neural networks in one sentence.\"),\n",
        "    (\"summary-3\", \"Summarize the concept of deep learning in one sentence.\"),\n",
        "    (\"translate-1\", \"Translate 'Hello, how are you?' to Spanish.\"),\n",
        "    (\"translate-2\", \"Translate 'Hello, how are you?' to French.\"),\n",
        "]\n",
        "\n",
        "batch_requests = create_batch_requests(prompts)\n",
        "print(f\"Created {len(batch_requests)} batch requests\")\n",
        "print(\"\\nExample request structure:\")\n",
        "print(json.dumps(batch_requests[0], indent=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Submit and monitor a batch job\n",
        "# Note: Batch processing is asynchronous - results are retrieved later\n",
        "\n",
        "def submit_batch(requests):\n",
        "    \"\"\"Submit a batch of requests for processing.\"\"\"\n",
        "    try:\n",
        "        # Create the batch\n",
        "        batch = client.messages.batches.create(requests=requests)\n",
        "        \n",
        "        print(f\"Batch created!\")\n",
        "        print(f\"  ID: {batch.id}\")\n",
        "        print(f\"  Status: {batch.processing_status}\")\n",
        "        print(f\"  Created: {batch.created_at}\")\n",
        "        \n",
        "        return batch\n",
        "    except Exception as e:\n",
        "        print(f\"Error creating batch: {e}\")\n",
        "        return None\n",
        "\n",
        "def check_batch_status(batch_id):\n",
        "    \"\"\"Check the status of a batch job.\"\"\"\n",
        "    try:\n",
        "        batch = client.messages.batches.retrieve(batch_id)\n",
        "        \n",
        "        print(f\"Batch Status: {batch.processing_status}\")\n",
        "        print(f\"  Request counts:\")\n",
        "        print(f\"    Processing: {batch.request_counts.processing}\")\n",
        "        print(f\"    Succeeded: {batch.request_counts.succeeded}\")\n",
        "        print(f\"    Errored: {batch.request_counts.errored}\")\n",
        "        print(f\"    Canceled: {batch.request_counts.canceled}\")\n",
        "        print(f\"    Expired: {batch.request_counts.expired}\")\n",
        "        \n",
        "        return batch\n",
        "    except Exception as e:\n",
        "        print(f\"Error checking batch: {e}\")\n",
        "        return None\n",
        "\n",
        "def get_batch_results(batch_id):\n",
        "    \"\"\"Retrieve results from a completed batch.\"\"\"\n",
        "    try:\n",
        "        results = []\n",
        "        for result in client.messages.batches.results(batch_id):\n",
        "            results.append({\n",
        "                \"custom_id\": result.custom_id,\n",
        "                \"result_type\": result.result.type,\n",
        "                \"response\": result.result.message.content[0].text if result.result.type == \"succeeded\" else None,\n",
        "                \"error\": result.result.error if result.result.type == \"errored\" else None\n",
        "            })\n",
        "        return results\n",
        "    except Exception as e:\n",
        "        print(f\"Error getting results: {e}\")\n",
        "        return []\n",
        "\n",
        "# Submit the batch (uncomment to run)\n",
        "# batch = submit_batch(batch_requests)\n",
        "# if batch:\n",
        "#     # Wait and check status\n",
        "#     time.sleep(5)\n",
        "#     check_batch_status(batch.id)\n",
        "\n",
        "print(\"Batch functions defined. Uncomment the code above to submit a real batch.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. PDF Document Processing\n",
        "\n",
        "Claude can analyze PDF documents directly. This is powerful for:\n",
        "- Document summarization\n",
        "- Information extraction\n",
        "- Question answering over documents\n",
        "- Contract analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# PDF Document Processing\n",
        "# Claude can analyze PDF files sent as base64-encoded content\n",
        "\n",
        "def analyze_pdf_from_url(pdf_url, question):\n",
        "    \"\"\"\n",
        "    Analyze a PDF document from a URL.\n",
        "    \n",
        "    Args:\n",
        "        pdf_url: URL to the PDF file\n",
        "        question: Question to ask about the document\n",
        "    \n",
        "    Returns:\n",
        "        Claude's analysis of the document\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Download and encode the PDF\n",
        "        pdf_data = base64.standard_b64encode(httpx.get(pdf_url).content).decode(\"utf-8\")\n",
        "        \n",
        "        response = client.messages.create(\n",
        "            model=MODEL,\n",
        "            max_tokens=2048,\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": [\n",
        "                        {\n",
        "                            \"type\": \"document\",\n",
        "                            \"source\": {\n",
        "                                \"type\": \"base64\",\n",
        "                                \"media_type\": \"application/pdf\",\n",
        "                                \"data\": pdf_data,\n",
        "                            },\n",
        "                        },\n",
        "                        {\n",
        "                            \"type\": \"text\",\n",
        "                            \"text\": question\n",
        "                        }\n",
        "                    ],\n",
        "                }\n",
        "            ],\n",
        "        )\n",
        "        \n",
        "        return response.content[0].text\n",
        "    except Exception as e:\n",
        "        return f\"Error analyzing PDF: {e}\"\n",
        "\n",
        "def analyze_pdf_from_file(file_path, question):\n",
        "    \"\"\"\n",
        "    Analyze a PDF document from a local file.\n",
        "    \n",
        "    Args:\n",
        "        file_path: Path to the local PDF file\n",
        "        question: Question to ask about the document\n",
        "    \n",
        "    Returns:\n",
        "        Claude's analysis of the document\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(file_path, \"rb\") as f:\n",
        "            pdf_data = base64.standard_b64encode(f.read()).decode(\"utf-8\")\n",
        "        \n",
        "        response = client.messages.create(\n",
        "            model=MODEL,\n",
        "            max_tokens=2048,\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": [\n",
        "                        {\n",
        "                            \"type\": \"document\",\n",
        "                            \"source\": {\n",
        "                                \"type\": \"base64\",\n",
        "                                \"media_type\": \"application/pdf\",\n",
        "                                \"data\": pdf_data,\n",
        "                            },\n",
        "                        },\n",
        "                        {\n",
        "                            \"type\": \"text\",\n",
        "                            \"text\": question\n",
        "                        }\n",
        "                    ],\n",
        "                }\n",
        "            ],\n",
        "        )\n",
        "        \n",
        "        return response.content[0].text\n",
        "    except FileNotFoundError:\n",
        "        return f\"File not found: {file_path}\"\n",
        "    except Exception as e:\n",
        "        return f\"Error analyzing PDF: {e}\"\n",
        "\n",
        "print(\"PDF analysis functions defined!\")\n",
        "print(\"\\nExample usage:\")\n",
        "print('  result = analyze_pdf_from_url(\"https://example.com/document.pdf\", \"Summarize this document\")')\n",
        "print('  result = analyze_pdf_from_file(\"./document.pdf\", \"What are the key points?\")')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Citations and Source Attribution\n",
        "\n",
        "Citations allow Claude to reference specific parts of provided documents, enabling:\n",
        "- Verifiable responses\n",
        "- Source tracking\n",
        "- Academic-style references\n",
        "- Fact-checking capabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Citations Example\n",
        "# Enable citations to get references to source documents\n",
        "\n",
        "def query_with_citations(documents, question):\n",
        "    \"\"\"\n",
        "    Query documents with citations enabled.\n",
        "    \n",
        "    Args:\n",
        "        documents: List of document dicts with 'title', 'content' keys\n",
        "        question: Question to ask about the documents\n",
        "    \n",
        "    Returns:\n",
        "        Response with citations\n",
        "    \"\"\"\n",
        "    # Build content with document sources\n",
        "    content = []\n",
        "    \n",
        "    for i, doc in enumerate(documents):\n",
        "        content.append({\n",
        "            \"type\": \"document\",\n",
        "            \"source\": {\n",
        "                \"type\": \"text\",\n",
        "                \"media_type\": \"text/plain\",\n",
        "                \"data\": doc[\"content\"]\n",
        "            },\n",
        "            \"title\": doc.get(\"title\", f\"Document {i+1}\"),\n",
        "            \"citations\": {\"enabled\": True}  # Enable citations for this document\n",
        "        })\n",
        "    \n",
        "    content.append({\n",
        "        \"type\": \"text\",\n",
        "        \"text\": question\n",
        "    })\n",
        "    \n",
        "    try:\n",
        "        response = client.messages.create(\n",
        "            model=MODEL,\n",
        "            max_tokens=1024,\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": content\n",
        "                }\n",
        "            ]\n",
        "        )\n",
        "        \n",
        "        # Process response with citations\n",
        "        result = {\n",
        "            \"text\": \"\",\n",
        "            \"citations\": []\n",
        "        }\n",
        "        \n",
        "        for block in response.content:\n",
        "            if block.type == \"text\":\n",
        "                result[\"text\"] += block.text\n",
        "                # Check for citations in the block\n",
        "                if hasattr(block, 'citations') and block.citations:\n",
        "                    for citation in block.citations:\n",
        "                        result[\"citations\"].append({\n",
        "                            \"document_title\": citation.document_title,\n",
        "                            \"cited_text\": citation.cited_text,\n",
        "                            \"start_index\": citation.start_char_index,\n",
        "                            \"end_index\": citation.end_char_index\n",
        "                        })\n",
        "        \n",
        "        return result\n",
        "    except Exception as e:\n",
        "        return {\"error\": str(e), \"text\": \"\", \"citations\": []}\n",
        "\n",
        "# Example documents\n",
        "sample_documents = [\n",
        "    {\n",
        "        \"title\": \"Python Overview\",\n",
        "        \"content\": \"\"\"Python is a high-level, interpreted programming language created by Guido van Rossum \n",
        "        and first released in 1991. Python's design philosophy emphasizes code readability with the use \n",
        "        of significant indentation. Python is dynamically typed and garbage-collected. It supports \n",
        "        multiple programming paradigms, including structured, object-oriented, and functional programming.\"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"Python Applications\",\n",
        "        \"content\": \"\"\"Python is widely used in web development, data science, artificial intelligence, \n",
        "        machine learning, automation, and scientific computing. Popular frameworks include Django and \n",
        "        Flask for web development, NumPy and Pandas for data analysis, and TensorFlow and PyTorch \n",
        "        for machine learning.\"\"\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# Query with citations\n",
        "result = query_with_citations(\n",
        "    sample_documents,\n",
        "    \"When was Python created and what are its main applications?\"\n",
        ")\n",
        "\n",
        "print(\"Response:\")\n",
        "print(\"-\" * 50)\n",
        "print(result[\"text\"])\n",
        "print(\"\\nCitations:\")\n",
        "print(\"-\" * 50)\n",
        "if result[\"citations\"]:\n",
        "    for i, citation in enumerate(result[\"citations\"], 1):\n",
        "        print(f\"{i}. From '{citation['document_title']}':\")\n",
        "        print(f\"   \\\"{citation['cited_text'][:100]}...\\\"\" if len(citation.get('cited_text', '')) > 100 else f\"   \\\"{citation.get('cited_text', '')}\\\"\")\n",
        "else:\n",
        "    print(\"No citations found (citations may require specific model support)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Building AI Agents\n",
        "\n",
        "AI Agents are autonomous systems that can:\n",
        "- Make decisions based on context\n",
        "- Use tools to accomplish tasks\n",
        "- Maintain state across interactions\n",
        "- Handle complex multi-step workflows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# AI Agent Implementation\n",
        "# A complete agent that can use tools and maintain conversation state\n",
        "\n",
        "import math\n",
        "\n",
        "class AIAgent:\n",
        "    \"\"\"\n",
        "    An AI Agent that can use tools to accomplish tasks.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, client, model=MODEL, system_prompt=None):\n",
        "        self.client = client\n",
        "        self.model = model\n",
        "        self.system_prompt = system_prompt or \"You are a helpful AI assistant with access to tools.\"\n",
        "        self.conversation_history = []\n",
        "        self.tools = []\n",
        "        self.tool_functions = {}\n",
        "        \n",
        "    def register_tool(self, name, description, parameters, function):\n",
        "        \"\"\"Register a tool that the agent can use.\"\"\"\n",
        "        self.tools.append({\n",
        "            \"name\": name,\n",
        "            \"description\": description,\n",
        "            \"input_schema\": parameters\n",
        "        })\n",
        "        self.tool_functions[name] = function\n",
        "        \n",
        "    def _execute_tool(self, tool_name, tool_input):\n",
        "        \"\"\"Execute a registered tool.\"\"\"\n",
        "        if tool_name in self.tool_functions:\n",
        "            try:\n",
        "                return self.tool_functions[tool_name](**tool_input)\n",
        "            except Exception as e:\n",
        "                return {\"error\": str(e)}\n",
        "        return {\"error\": f\"Unknown tool: {tool_name}\"}\n",
        "    \n",
        "    def run(self, user_message, max_iterations=10):\n",
        "        \"\"\"\n",
        "        Run the agent with a user message.\n",
        "        Handles tool use automatically until completion.\n",
        "        \"\"\"\n",
        "        self.conversation_history.append({\n",
        "            \"role\": \"user\",\n",
        "            \"content\": user_message\n",
        "        })\n",
        "        \n",
        "        iteration = 0\n",
        "        while iteration < max_iterations:\n",
        "            iteration += 1\n",
        "            \n",
        "            # Make API call\n",
        "            response = self.client.messages.create(\n",
        "                model=self.model,\n",
        "                max_tokens=2048,\n",
        "                system=self.system_prompt,\n",
        "                tools=self.tools if self.tools else None,\n",
        "                messages=self.conversation_history\n",
        "            )\n",
        "            \n",
        "            # Check if we need to use tools\n",
        "            if response.stop_reason == \"tool_use\":\n",
        "                # Process tool calls\n",
        "                tool_results = []\n",
        "                for block in response.content:\n",
        "                    if block.type == \"tool_use\":\n",
        "                        print(f\"  ðŸ”§ Using tool: {block.name}\")\n",
        "                        result = self._execute_tool(block.name, block.input)\n",
        "                        print(f\"     Result: {json.dumps(result)[:100]}...\")\n",
        "                        tool_results.append({\n",
        "                            \"type\": \"tool_result\",\n",
        "                            \"tool_use_id\": block.id,\n",
        "                            \"content\": json.dumps(result)\n",
        "                        })\n",
        "                \n",
        "                # Add assistant response and tool results\n",
        "                self.conversation_history.append({\n",
        "                    \"role\": \"assistant\",\n",
        "                    \"content\": response.content\n",
        "                })\n",
        "                self.conversation_history.append({\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": tool_results\n",
        "                })\n",
        "            else:\n",
        "                # Done - extract final response\n",
        "                final_response = \"\"\n",
        "                for block in response.content:\n",
        "                    if hasattr(block, \"text\"):\n",
        "                        final_response += block.text\n",
        "                \n",
        "                self.conversation_history.append({\n",
        "                    \"role\": \"assistant\",\n",
        "                    \"content\": final_response\n",
        "                })\n",
        "                \n",
        "                return final_response\n",
        "        \n",
        "        return \"Max iterations reached without completion.\"\n",
        "    \n",
        "    def reset(self):\n",
        "        \"\"\"Reset conversation history.\"\"\"\n",
        "        self.conversation_history = []\n",
        "\n",
        "print(\"AIAgent class defined!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create and use an AI Agent with tools\n",
        "\n",
        "# Create agent\n",
        "agent = AIAgent(\n",
        "    client,\n",
        "    system_prompt=\"You are a helpful research assistant. Use tools when needed to answer questions accurately.\"\n",
        ")\n",
        "\n",
        "# Register calculator tool\n",
        "agent.register_tool(\n",
        "    name=\"calculator\",\n",
        "    description=\"Perform mathematical calculations\",\n",
        "    parameters={\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"expression\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"Math expression to evaluate (e.g., '2 + 2', 'sqrt(16)')\"\n",
        "            }\n",
        "        },\n",
        "        \"required\": [\"expression\"]\n",
        "    },\n",
        "    function=lambda expression: {\n",
        "        \"result\": eval(expression, {\"__builtins__\": {}, \"sqrt\": math.sqrt, \"pow\": pow, \"abs\": abs})\n",
        "    }\n",
        ")\n",
        "\n",
        "# Register knowledge base tool\n",
        "knowledge_base = {\n",
        "    \"python\": \"Python is a programming language created in 1991 by Guido van Rossum.\",\n",
        "    \"javascript\": \"JavaScript is a programming language created in 1995 by Brendan Eich.\",\n",
        "    \"anthropic\": \"Anthropic is an AI safety company founded in 2021, creator of Claude.\"\n",
        "}\n",
        "\n",
        "agent.register_tool(\n",
        "    name=\"lookup\",\n",
        "    description=\"Look up information about a topic\",\n",
        "    parameters={\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"topic\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"Topic to look up (e.g., 'python', 'javascript', 'anthropic')\"\n",
        "            }\n",
        "        },\n",
        "        \"required\": [\"topic\"]\n",
        "    },\n",
        "    function=lambda topic: {\n",
        "        \"info\": knowledge_base.get(topic.lower(), f\"No information found for '{topic}'\")\n",
        "    }\n",
        ")\n",
        "\n",
        "print(\"Agent created with 2 tools: calculator, lookup\")\n",
        "print(\"\\nRunning agent...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "result = agent.run(\"What is Python and what is 25 * 4 + 10?\")\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"\\nFinal Response:\")\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Production Best Practices\n",
        "\n",
        "Key patterns for production deployments:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Production-Ready Client Wrapper\n",
        "import random\n",
        "from typing import Optional, List, Dict, Any\n",
        "from dataclasses import dataclass\n",
        "from datetime import datetime\n",
        "\n",
        "@dataclass\n",
        "class APICallMetrics:\n",
        "    \"\"\"Metrics for API calls.\"\"\"\n",
        "    timestamp: datetime\n",
        "    model: str\n",
        "    input_tokens: int\n",
        "    output_tokens: int\n",
        "    latency_ms: float\n",
        "    success: bool\n",
        "    error: Optional[str] = None\n",
        "\n",
        "class ProductionClient:\n",
        "    \"\"\"\n",
        "    Production-ready Anthropic client with:\n",
        "    - Automatic retries with exponential backoff\n",
        "    - Request/response logging\n",
        "    - Metrics collection\n",
        "    - Rate limiting\n",
        "    - Circuit breaker pattern\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, client, max_retries=3, base_delay=1.0):\n",
        "        self.client = client\n",
        "        self.max_retries = max_retries\n",
        "        self.base_delay = base_delay\n",
        "        self.metrics: List[APICallMetrics] = []\n",
        "        self.consecutive_failures = 0\n",
        "        self.circuit_open = False\n",
        "        self.circuit_open_until = None\n",
        "        \n",
        "    def _should_retry(self, exception) -> bool:\n",
        "        \"\"\"Determine if we should retry based on exception type.\"\"\"\n",
        "        retryable_errors = (\n",
        "            anthropic.RateLimitError,\n",
        "            anthropic.APIConnectionError,\n",
        "            anthropic.InternalServerError,\n",
        "        )\n",
        "        return isinstance(exception, retryable_errors)\n",
        "    \n",
        "    def _calculate_delay(self, attempt: int) -> float:\n",
        "        \"\"\"Calculate delay with exponential backoff and jitter.\"\"\"\n",
        "        delay = self.base_delay * (2 ** attempt)\n",
        "        jitter = random.uniform(0, 0.1 * delay)\n",
        "        return min(delay + jitter, 60)  # Cap at 60 seconds\n",
        "    \n",
        "    def _check_circuit(self) -> bool:\n",
        "        \"\"\"Check if circuit breaker allows requests.\"\"\"\n",
        "        if not self.circuit_open:\n",
        "            return True\n",
        "        if datetime.now() > self.circuit_open_until:\n",
        "            self.circuit_open = False\n",
        "            self.consecutive_failures = 0\n",
        "            return True\n",
        "        return False\n",
        "    \n",
        "    def _record_failure(self):\n",
        "        \"\"\"Record a failure for circuit breaker.\"\"\"\n",
        "        self.consecutive_failures += 1\n",
        "        if self.consecutive_failures >= 5:\n",
        "            self.circuit_open = True\n",
        "            from datetime import timedelta\n",
        "            self.circuit_open_until = datetime.now() + timedelta(seconds=30)\n",
        "    \n",
        "    def create_message(self, **kwargs) -> Any:\n",
        "        \"\"\"Create a message with production safeguards.\"\"\"\n",
        "        if not self._check_circuit():\n",
        "            raise Exception(\"Circuit breaker is open - too many recent failures\")\n",
        "        \n",
        "        start_time = time.time()\n",
        "        last_exception = None\n",
        "        \n",
        "        for attempt in range(self.max_retries):\n",
        "            try:\n",
        "                response = self.client.messages.create(**kwargs)\n",
        "                \n",
        "                # Record success metrics\n",
        "                latency = (time.time() - start_time) * 1000\n",
        "                self.metrics.append(APICallMetrics(\n",
        "                    timestamp=datetime.now(),\n",
        "                    model=kwargs.get(\"model\", \"unknown\"),\n",
        "                    input_tokens=response.usage.input_tokens,\n",
        "                    output_tokens=response.usage.output_tokens,\n",
        "                    latency_ms=latency,\n",
        "                    success=True\n",
        "                ))\n",
        "                \n",
        "                self.consecutive_failures = 0\n",
        "                return response\n",
        "                \n",
        "            except Exception as e:\n",
        "                last_exception = e\n",
        "                \n",
        "                if self._should_retry(e) and attempt < self.max_retries - 1:\n",
        "                    delay = self._calculate_delay(attempt)\n",
        "                    print(f\"Retrying in {delay:.2f}s (attempt {attempt + 1}/{self.max_retries})\")\n",
        "                    time.sleep(delay)\n",
        "                else:\n",
        "                    break\n",
        "        \n",
        "        # Record failure\n",
        "        latency = (time.time() - start_time) * 1000\n",
        "        self.metrics.append(APICallMetrics(\n",
        "            timestamp=datetime.now(),\n",
        "            model=kwargs.get(\"model\", \"unknown\"),\n",
        "            input_tokens=0,\n",
        "            output_tokens=0,\n",
        "            latency_ms=latency,\n",
        "            success=False,\n",
        "            error=str(last_exception)\n",
        "        ))\n",
        "        \n",
        "        self._record_failure()\n",
        "        raise last_exception\n",
        "    \n",
        "    def get_metrics_summary(self) -> Dict:\n",
        "        \"\"\"Get a summary of collected metrics.\"\"\"\n",
        "        if not self.metrics:\n",
        "            return {\"message\": \"No metrics collected yet\"}\n",
        "        \n",
        "        successful = [m for m in self.metrics if m.success]\n",
        "        failed = [m for m in self.metrics if not m.success]\n",
        "        \n",
        "        return {\n",
        "            \"total_calls\": len(self.metrics),\n",
        "            \"successful\": len(successful),\n",
        "            \"failed\": len(failed),\n",
        "            \"success_rate\": len(successful) / len(self.metrics) * 100,\n",
        "            \"total_input_tokens\": sum(m.input_tokens for m in successful),\n",
        "            \"total_output_tokens\": sum(m.output_tokens for m in successful),\n",
        "            \"avg_latency_ms\": sum(m.latency_ms for m in successful) / len(successful) if successful else 0,\n",
        "            \"circuit_breaker_open\": self.circuit_open\n",
        "        }\n",
        "\n",
        "# Create production client\n",
        "prod_client = ProductionClient(client)\n",
        "\n",
        "# Test it\n",
        "response = prod_client.create_message(\n",
        "    model=MODEL,\n",
        "    max_tokens=100,\n",
        "    messages=[{\"role\": \"user\", \"content\": \"Hello!\"}]\n",
        ")\n",
        "\n",
        "print(\"Response:\", response.content[0].text)\n",
        "print(\"\\nMetrics Summary:\")\n",
        "print(json.dumps(prod_client.get_metrics_summary(), indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Practice Exercises"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exercise 1: Create an agent with a custom tool\n",
        "# Add a \"get_time\" tool that returns the current time\n",
        "# Your code here:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exercise 2: Implement a batch processor for sentiment analysis\n",
        "# Process 10 product reviews and classify them as positive/negative\n",
        "# Your code here:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exercise 3: Extend ProductionClient with request logging to a file\n",
        "# Your code here:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "In this specialty notebook, you learned:\n",
        "\n",
        "1. **Extended Thinking** - Chain of thought reasoning for complex problems\n",
        "2. **Batch Processing** - High-volume operations with cost optimization\n",
        "3. **PDF Processing** - Document analysis and information extraction\n",
        "4. **Citations** - Source attribution for verifiable responses\n",
        "5. **AI Agents** - Building autonomous systems with tool use\n",
        "6. **Production Patterns** - Retries, circuit breakers, and metrics collection\n",
        "\n",
        "---\n",
        "\n",
        "## Learning Path Complete!\n",
        "\n",
        "Congratulations! You've completed the Anthropic SDK learning path:\n",
        "\n",
        "| Level | Topics Covered |\n",
        "|-------|---------------|\n",
        "| **Entry** | Client setup, basic API calls, messages, system prompts |\n",
        "| **Middle** | Streaming, temperature, vision, token counting |\n",
        "| **Advanced** | Tool use, JSON output, prompt caching, async operations |\n",
        "| **Specialty** | Extended thinking, batches, PDFs, citations, agents |\n",
        "\n",
        "### Next Steps:\n",
        "- Build a real application using these concepts\n",
        "- Explore the [Anthropic Documentation](https://docs.anthropic.com/)\n",
        "- Join the [Anthropic Discord](https://discord.gg/anthropic) community\n",
        "- Check out the [Anthropic Cookbook](https://github.com/anthropics/anthropic-cookbook) for more examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
