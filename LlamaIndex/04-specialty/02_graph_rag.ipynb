{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GraphRAG: Knowledge Graph-Enhanced Retrieval\n",
    "\n",
    "GraphRAG combines traditional RAG with knowledge graphs to capture entity relationships and enable more sophisticated reasoning.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "1. Understand knowledge graphs and their benefits for RAG\n",
    "2. Extract entities and relationships from documents\n",
    "3. Build a knowledge graph index\n",
    "4. Query using graph traversal\n",
    "5. Combine vector search with graph-based retrieval\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is GraphRAG?\n",
    "\n",
    "Traditional RAG retrieves text chunks based on similarity. **GraphRAG** adds:\n",
    "\n",
    "- **Entity extraction**: Identify people, places, concepts\n",
    "- **Relationship mapping**: How entities connect\n",
    "- **Graph traversal**: Follow relationships for context\n",
    "\n",
    "### When to Use GraphRAG\n",
    "\n",
    "| Use Case | Vector RAG | GraphRAG |\n",
    "|----------|------------|----------|\n",
    "| Simple Q&A | ✓ | |\n",
    "| Entity relationships | | ✓ |\n",
    "| Multi-hop reasoning | | ✓ |\n",
    "| Complex queries | | ✓ |\n",
    "| Document similarity | ✓ | |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from llama_index.core import (\n",
    "    Settings,\n",
    "    KnowledgeGraphIndex,\n",
    "    SimpleDirectoryReader,\n",
    "    Document,\n",
    "    StorageContext,\n",
    ")\n",
    "from llama_index.core.graph_stores import SimpleGraphStore\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "# Configure\n",
    "Settings.llm = OpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")\n",
    "Settings.chunk_size = 512\n",
    "\n",
    "print(\"✓ Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Knowledge Graph Basics\n",
    "\n",
    "A knowledge graph consists of:\n",
    "- **Nodes**: Entities (people, concepts, things)\n",
    "- **Edges**: Relationships between entities\n",
    "- **Properties**: Attributes of nodes and edges\n",
    "\n",
    "Example: `(Python) --[is_a]--> (Programming Language)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample documents with rich entity relationships\n",
    "documents = [\n",
    "    Document(text=\"\"\"\n",
    "Python is a programming language created by Guido van Rossum in 1991.\n",
    "Python is widely used in machine learning and data science.\n",
    "Guido van Rossum worked at Google and later at Dropbox.\n",
    "Python's design philosophy emphasizes code readability.\n",
    "    \"\"\"),\n",
    "    Document(text=\"\"\"\n",
    "Machine learning is a subset of artificial intelligence.\n",
    "Deep learning is a type of machine learning that uses neural networks.\n",
    "TensorFlow and PyTorch are popular deep learning frameworks.\n",
    "TensorFlow was developed by Google Brain team.\n",
    "PyTorch was developed by Meta AI (formerly Facebook AI Research).\n",
    "    \"\"\"),\n",
    "    Document(text=\"\"\"\n",
    "Neural networks are inspired by biological neurons.\n",
    "Geoffrey Hinton is known as the godfather of deep learning.\n",
    "Geoffrey Hinton worked at Google and the University of Toronto.\n",
    "Yann LeCun developed convolutional neural networks.\n",
    "Yann LeCun is the Chief AI Scientist at Meta.\n",
    "    \"\"\"),\n",
    "]\n",
    "\n",
    "print(f\"Created {len(documents)} documents with entity relationships\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Building a Knowledge Graph Index\n",
    "\n",
    "LlamaIndex can automatically extract entities and relationships:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple graph store (in-memory)\n",
    "graph_store = SimpleGraphStore()\n",
    "\n",
    "# Create storage context with graph store\n",
    "storage_context = StorageContext.from_defaults(graph_store=graph_store)\n",
    "\n",
    "# Build knowledge graph index\n",
    "# This extracts entities and relationships using the LLM\n",
    "print(\"Building knowledge graph index...\")\n",
    "print(\"(This extracts entities and relationships using the LLM)\\n\")\n",
    "\n",
    "kg_index = KnowledgeGraphIndex.from_documents(\n",
    "    documents,\n",
    "    storage_context=storage_context,\n",
    "    max_triplets_per_chunk=10,\n",
    "    show_progress=True,\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Knowledge graph index built!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the extracted knowledge graph\n",
    "print(\"Extracted triplets (subject, predicate, object):\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Get all triplets from the graph\n",
    "triplets = []\n",
    "for node_id, node_data in graph_store._data.items():\n",
    "    if hasattr(node_data, 'edges'):\n",
    "        for edge in node_data.edges:\n",
    "            triplets.append((node_id, edge.predicate, edge.target))\n",
    "\n",
    "# Display sample triplets\n",
    "for subject, predicate, obj in triplets[:15]:\n",
    "    print(f\"  ({subject}) --[{predicate}]--> ({obj})\")\n",
    "\n",
    "if len(triplets) > 15:\n",
    "    print(f\"  ... and {len(triplets) - 15} more triplets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Querying the Knowledge Graph\n",
    "\n",
    "Query engines for knowledge graphs can use different retrieval modes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create query engine with keyword mode\n",
    "# This extracts keywords from the query and matches graph entities\n",
    "kg_query_engine = kg_index.as_query_engine(\n",
    "    include_text=True,  # Include original text context\n",
    "    response_mode=\"tree_summarize\",\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(\"✓ Query engine ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test entity relationship queries\n",
    "queries = [\n",
    "    \"Who created Python?\",\n",
    "    \"What is the relationship between TensorFlow and Google?\",\n",
    "    \"Who are the key figures in deep learning?\",\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Query: {query}\")\n",
    "    print(\"-\" * 60)\n",
    "    response = kg_query_engine.query(query)\n",
    "    print(f\"Answer: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Multi-hop Reasoning\n",
    "\n",
    "Knowledge graphs enable multi-hop reasoning - following chains of relationships:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-hop query example\n",
    "# This requires traversing multiple relationships\n",
    "multi_hop_queries = [\n",
    "    \"Which companies have employed people who contributed to deep learning?\",\n",
    "    \"What frameworks are used for the field that Python is used in?\",\n",
    "    \"What do Geoffrey Hinton and Yann LeCun have in common?\",\n",
    "]\n",
    "\n",
    "for query in multi_hop_queries:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Multi-hop Query: {query}\")\n",
    "    print(\"-\" * 60)\n",
    "    response = kg_query_engine.query(query)\n",
    "    print(f\"Answer: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Custom Entity and Relationship Extraction\n",
    "\n",
    "You can customize entity extraction for your domain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import PromptTemplate\n",
    "\n",
    "# Custom triplet extraction prompt\n",
    "CUSTOM_KG_TRIPLET_EXTRACT_PROMPT = PromptTemplate(\n",
    "    \"\"\"Extract knowledge graph triplets from the following text.\n",
    "Focus on:\n",
    "- PERSON entities (researchers, developers, founders)\n",
    "- ORGANIZATION entities (companies, universities, research labs)\n",
    "- TECHNOLOGY entities (programming languages, frameworks, algorithms)\n",
    "- CONCEPT entities (fields of study, methodologies)\n",
    "\n",
    "For relationships, use predicates like:\n",
    "- created_by, developed_by, founded_by\n",
    "- works_at, worked_at\n",
    "- is_part_of, is_type_of\n",
    "- used_for, enables\n",
    "\n",
    "Text: {text}\n",
    "\n",
    "Extract triplets in the format: (subject, predicate, object)\n",
    "Return up to {max_knowledge_triplets} triplets.\n",
    "\n",
    "Triplets:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "print(\"✓ Custom extraction prompt defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build knowledge graph with custom prompt\n",
    "custom_graph_store = SimpleGraphStore()\n",
    "custom_storage_context = StorageContext.from_defaults(graph_store=custom_graph_store)\n",
    "\n",
    "print(\"Building knowledge graph with custom extraction...\")\n",
    "\n",
    "custom_kg_index = KnowledgeGraphIndex.from_documents(\n",
    "    documents,\n",
    "    storage_context=custom_storage_context,\n",
    "    max_triplets_per_chunk=10,\n",
    "    kg_triplet_extract_template=CUSTOM_KG_TRIPLET_EXTRACT_PROMPT,\n",
    "    show_progress=True,\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Custom knowledge graph built!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Hybrid Retrieval: Combining Vector and Graph\n",
    "\n",
    "Combine vector similarity search with graph traversal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.query_engine import RouterQueryEngine\n",
    "from llama_index.core.selectors import LLMSingleSelector\n",
    "from llama_index.core.tools import QueryEngineTool\n",
    "\n",
    "# Create vector index from same documents\n",
    "vector_index = VectorStoreIndex.from_documents(documents)\n",
    "vector_query_engine = vector_index.as_query_engine()\n",
    "\n",
    "# Create tools for both approaches\n",
    "vector_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=vector_query_engine,\n",
    "    description=\"Useful for questions about general concepts, definitions, \"\n",
    "                \"and when looking for similar content. Good for 'what is' questions.\",\n",
    ")\n",
    "\n",
    "kg_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=kg_query_engine,\n",
    "    description=\"Useful for questions about relationships between entities, \"\n",
    "                \"'who created/works at/developed' questions, and tracing connections.\",\n",
    ")\n",
    "\n",
    "# Create router that selects best approach\n",
    "hybrid_query_engine = RouterQueryEngine(\n",
    "    selector=LLMSingleSelector.from_defaults(),\n",
    "    query_engine_tools=[vector_tool, kg_tool],\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(\"✓ Hybrid query engine ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test hybrid retrieval\n",
    "hybrid_queries = [\n",
    "    \"What is deep learning?\",  # Should use vector (concept question)\n",
    "    \"Who developed PyTorch?\",  # Should use KG (relationship question)\n",
    "    \"What companies are involved in AI research?\",  # Could use either\n",
    "]\n",
    "\n",
    "for query in hybrid_queries:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Query: {query}\")\n",
    "    print(\"-\" * 60)\n",
    "    response = hybrid_query_engine.query(query)\n",
    "    print(f\"Answer: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualizing the Knowledge Graph\n",
    "\n",
    "Visualize the extracted knowledge graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple text visualization of the graph\n",
    "def visualize_graph_text(graph_store):\n",
    "    \"\"\"Create a text visualization of the knowledge graph.\"\"\"\n",
    "    print(\"\\n=== Knowledge Graph Visualization ===\")\n",
    "    print(\"\\nEntities and their relationships:\\n\")\n",
    "    \n",
    "    entities = set()\n",
    "    relationships = []\n",
    "    \n",
    "    for node_id, node_data in graph_store._data.items():\n",
    "        entities.add(node_id)\n",
    "        if hasattr(node_data, 'edges'):\n",
    "            for edge in node_data.edges:\n",
    "                entities.add(edge.target)\n",
    "                relationships.append((node_id, edge.predicate, edge.target))\n",
    "    \n",
    "    print(f\"Total entities: {len(entities)}\")\n",
    "    print(f\"Total relationships: {len(relationships)}\")\n",
    "    \n",
    "    # Show entity categories\n",
    "    print(\"\\n--- Sample Entities ---\")\n",
    "    for i, entity in enumerate(sorted(entities)[:20]):\n",
    "        print(f\"  • {entity}\")\n",
    "    \n",
    "    print(\"\\n--- Sample Relationships ---\")\n",
    "    for subj, pred, obj in relationships[:15]:\n",
    "        print(f\"  {subj} --[{pred}]--> {obj}\")\n",
    "\n",
    "visualize_graph_text(graph_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary\n",
    "\n",
    "You've learned GraphRAG techniques with LlamaIndex:\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "| Concept | Description |\n",
    "|---------|-------------|\n",
    "| **Knowledge Graph** | Nodes (entities) + Edges (relationships) |\n",
    "| **Triplet Extraction** | (subject, predicate, object) from text |\n",
    "| **Multi-hop Reasoning** | Following relationship chains |\n",
    "| **Hybrid Retrieval** | Combining vector + graph approaches |\n",
    "\n",
    "### When to Use GraphRAG\n",
    "\n",
    "1. **Entity-heavy domains**: People, organizations, products\n",
    "2. **Relationship queries**: \"Who works at...\", \"What created...\"\n",
    "3. **Multi-hop questions**: Require traversing multiple relationships\n",
    "4. **Knowledge integration**: Combining info across documents\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "In the next notebook, we'll explore LlamaCloud for managed services."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercises\n",
    "\n",
    "1. **Domain-specific extraction**: Create custom prompts for your domain\n",
    "\n",
    "2. **Neo4j integration**: Use Neo4j as a persistent graph store\n",
    "\n",
    "3. **Graph visualization**: Use networkx or pyvis for interactive visualization\n",
    "\n",
    "4. **Entity resolution**: Handle duplicate entities with different names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise space\n",
    "# Build your knowledge graph application here!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
