{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LlamaCloud: Managed RAG Services\n",
    "\n",
    "LlamaCloud provides managed services for document processing and RAG, including LlamaParse for document parsing and managed indexes.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "1. Understand LlamaCloud services and pricing\n",
    "2. Use LlamaParse for document processing\n",
    "3. Work with managed indexes\n",
    "4. Integrate LlamaCloud with local pipelines\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LlamaCloud Overview\n",
    "\n",
    "LlamaCloud offers several services:\n",
    "\n",
    "| Service | Description | Use Case |\n",
    "|---------|-------------|----------|\n",
    "| **LlamaParse** | Advanced document parsing | Complex PDFs, tables, images |\n",
    "| **LlamaExtract** | Structured data extraction | Form processing |\n",
    "| **Managed Index** | Cloud-hosted vector index | Production RAG |\n",
    "\n",
    "### Getting Started\n",
    "\n",
    "1. Sign up at [cloud.llamaindex.ai](https://cloud.llamaindex.ai)\n",
    "2. Get your API key from the dashboard\n",
    "3. Set `LLAMA_CLOUD_API_KEY` in your `.env` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from llama_index.core import Settings, VectorStoreIndex\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "# Configure\n",
    "Settings.llm = OpenAI(model=\"gpt-4o-mini\")\n",
    "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")\n",
    "\n",
    "# Check LlamaCloud API key\n",
    "llama_cloud_key = os.getenv(\"LLAMA_CLOUD_API_KEY\")\n",
    "if llama_cloud_key:\n",
    "    print(\"✓ LlamaCloud API key configured\")\n",
    "else:\n",
    "    print(\"✗ LlamaCloud API key not found\")\n",
    "    print(\"  Some features in this notebook require a LlamaCloud account.\")\n",
    "    print(\"  Sign up at: https://cloud.llamaindex.ai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. LlamaParse: Advanced Document Parsing\n",
    "\n",
    "LlamaParse excels at parsing complex documents that standard tools struggle with:\n",
    "- Multi-column layouts\n",
    "- Tables with merged cells\n",
    "- Images and figures\n",
    "- Mathematical formulas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LlamaParse requires: pip install llama-parse\n",
    "try:\n",
    "    from llama_parse import LlamaParse\n",
    "    LLAMAPARSE_AVAILABLE = True\n",
    "    print(\"✓ LlamaParse is available\")\n",
    "except ImportError:\n",
    "    LLAMAPARSE_AVAILABLE = False\n",
    "    print(\"✗ LlamaParse not installed. Run: pip install llama-parse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LLAMAPARSE_AVAILABLE and llama_cloud_key:\n",
    "    # Initialize LlamaParse\n",
    "    parser = LlamaParse(\n",
    "        api_key=llama_cloud_key,\n",
    "        result_type=\"markdown\",  # or \"text\"\n",
    "        verbose=True,\n",
    "        language=\"en\",\n",
    "    )\n",
    "    print(\"✓ LlamaParse initialized!\")\n",
    "else:\n",
    "    print(\"LlamaParse demo requires API key. Showing example code instead.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Parse a PDF document\n",
    "# (Replace with your actual PDF file path)\n",
    "\n",
    "EXAMPLE_PARSE_CODE = '''\n",
    "# Parse a single document\n",
    "documents = parser.load_data(\"./sample.pdf\")\n",
    "\n",
    "# The parsed content is in markdown format\n",
    "for doc in documents:\n",
    "    print(f\"Parsed content preview:\")\n",
    "    print(doc.text[:500])\n",
    "    print(f\"\\\\nMetadata: {doc.metadata}\")\n",
    "'''\n",
    "\n",
    "print(\"Example LlamaParse usage:\")\n",
    "print(EXAMPLE_PARSE_CODE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LlamaParse Configuration Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced LlamaParse configuration\n",
    "ADVANCED_CONFIG = '''\n",
    "parser = LlamaParse(\n",
    "    api_key=llama_cloud_key,\n",
    "    \n",
    "    # Output format\n",
    "    result_type=\"markdown\",  # \"text\" or \"markdown\"\n",
    "    \n",
    "    # Language settings\n",
    "    language=\"en\",\n",
    "    \n",
    "    # Parsing options\n",
    "    skip_diagonal_text=False,\n",
    "    invalidate_cache=False,\n",
    "    do_not_cache=False,\n",
    "    \n",
    "    # Custom instructions for parsing\n",
    "    parsing_instruction=\"Extract all tables as markdown. Preserve mathematical formulas.\",\n",
    "    \n",
    "    # Premium features (requires higher tier)\n",
    "    use_vendor_multimodal_model=False,\n",
    "    vendor_multimodal_model_name=None,\n",
    ")\n",
    "'''\n",
    "\n",
    "print(\"Advanced LlamaParse configuration:\")\n",
    "print(ADVANCED_CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Using LlamaParse with RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete pipeline with LlamaParse\n",
    "LLAMAPARSE_RAG_CODE = '''\n",
    "from llama_parse import LlamaParse\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.core.node_parser import MarkdownElementNodeParser\n",
    "\n",
    "# Initialize parser\n",
    "parser = LlamaParse(\n",
    "    api_key=os.getenv(\"LLAMA_CLOUD_API_KEY\"),\n",
    "    result_type=\"markdown\",\n",
    ")\n",
    "\n",
    "# Use as file extractor in SimpleDirectoryReader\n",
    "file_extractor = {\n",
    "    \".pdf\": parser,\n",
    "}\n",
    "\n",
    "# Load documents\n",
    "documents = SimpleDirectoryReader(\n",
    "    input_dir=\"./documents\",\n",
    "    file_extractor=file_extractor,\n",
    ").load_data()\n",
    "\n",
    "# Use markdown-aware node parser for better chunking\n",
    "node_parser = MarkdownElementNodeParser(\n",
    "    llm=Settings.llm,\n",
    "    num_workers=4,\n",
    ")\n",
    "\n",
    "# Get nodes\n",
    "nodes = node_parser.get_nodes_from_documents(documents)\n",
    "\n",
    "# Build index\n",
    "index = VectorStoreIndex(nodes=nodes)\n",
    "\n",
    "# Query\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What are the key findings?\")\n",
    "print(response)\n",
    "'''\n",
    "\n",
    "print(\"Complete LlamaParse + RAG pipeline:\")\n",
    "print(LLAMAPARSE_RAG_CODE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. LlamaCloud Managed Index\n",
    "\n",
    "LlamaCloud offers managed vector indexes that handle:\n",
    "- Document ingestion\n",
    "- Embedding generation\n",
    "- Vector storage and retrieval\n",
    "- Automatic updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Managed Index example code\n",
    "MANAGED_INDEX_CODE = '''\n",
    "from llama_index.indices.managed.llama_cloud import LlamaCloudIndex\n",
    "\n",
    "# Create a new managed index\n",
    "index = LlamaCloudIndex.from_documents(\n",
    "    documents,\n",
    "    name=\"my-production-index\",\n",
    "    project_name=\"my-project\",\n",
    "    api_key=os.getenv(\"LLAMA_CLOUD_API_KEY\"),\n",
    ")\n",
    "\n",
    "# Or connect to existing index\n",
    "index = LlamaCloudIndex(\n",
    "    name=\"my-production-index\",\n",
    "    project_name=\"my-project\",\n",
    "    api_key=os.getenv(\"LLAMA_CLOUD_API_KEY\"),\n",
    ")\n",
    "\n",
    "# Query the managed index\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What is the main topic?\")\n",
    "print(response)\n",
    "\n",
    "# Add more documents to existing index\n",
    "index.insert_documents(new_documents)\n",
    "'''\n",
    "\n",
    "print(\"LlamaCloud Managed Index usage:\")\n",
    "print(MANAGED_INDEX_CODE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. LlamaExtract: Structured Data Extraction\n",
    "\n",
    "Extract structured data from documents using schemas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LlamaExtract example\n",
    "LLAMA_EXTRACT_CODE = '''\n",
    "from llama_cloud import LlamaExtract\n",
    "from pydantic import BaseModel\n",
    "from typing import List, Optional\n",
    "\n",
    "# Define extraction schema\n",
    "class Invoice(BaseModel):\n",
    "    \"\"\"Schema for invoice extraction.\"\"\"\n",
    "    invoice_number: str\n",
    "    date: str\n",
    "    vendor_name: str\n",
    "    total_amount: float\n",
    "    line_items: List[dict]\n",
    "\n",
    "class ContactInfo(BaseModel):\n",
    "    \"\"\"Schema for contact information.\"\"\"\n",
    "    name: str\n",
    "    email: Optional[str]\n",
    "    phone: Optional[str]\n",
    "    company: Optional[str]\n",
    "\n",
    "# Initialize extractor\n",
    "extractor = LlamaExtract(\n",
    "    api_key=os.getenv(\"LLAMA_CLOUD_API_KEY\"),\n",
    ")\n",
    "\n",
    "# Extract structured data\n",
    "result = extractor.extract(\n",
    "    documents=[\"invoice.pdf\"],\n",
    "    schema=Invoice,\n",
    ")\n",
    "\n",
    "# Access extracted data\n",
    "for item in result:\n",
    "    invoice = Invoice(**item)\n",
    "    print(f\"Invoice: {invoice.invoice_number}\")\n",
    "    print(f\"Total: ${invoice.total_amount}\")\n",
    "'''\n",
    "\n",
    "print(\"LlamaExtract structured extraction:\")\n",
    "print(LLAMA_EXTRACT_CODE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Comparing Local vs Cloud\n",
    "\n",
    "When to use LlamaCloud vs local processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = \"\"\"\n",
    "╔══════════════════════╦═══════════════════════════╦═══════════════════════════╗\n",
    "║ Aspect               ║ Local Processing          ║ LlamaCloud                ║\n",
    "╠══════════════════════╬═══════════════════════════╬═══════════════════════════╣\n",
    "║ Setup                ║ More configuration        ║ Quick setup               ║\n",
    "║ Cost                 ║ Compute costs only        ║ Pay per document/query    ║\n",
    "║ PDF Quality          ║ Basic extraction          ║ Best-in-class parsing     ║\n",
    "║ Scaling              ║ Manual infrastructure     ║ Automatic scaling         ║\n",
    "║ Data Privacy         ║ Data stays local          ║ Data sent to cloud        ║\n",
    "║ Maintenance          ║ Self-managed              ║ Managed service           ║\n",
    "║ Complex Documents    ║ Limited capability        ║ Excellent support         ║\n",
    "╚══════════════════════╩═══════════════════════════╩═══════════════════════════╝\n",
    "\n",
    "RECOMMENDATION:\n",
    "- Use LlamaCloud for: Complex PDFs, production systems, quick prototypes\n",
    "- Use Local for: Simple documents, data privacy requirements, cost control\n",
    "\"\"\"\n",
    "\n",
    "print(comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Local Fallback Pattern\n",
    "\n",
    "A pattern for using LlamaCloud with local fallback:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Document\n",
    "from pathlib import Path\n",
    "\n",
    "class HybridDocumentLoader:\n",
    "    \"\"\"Load documents with LlamaCloud fallback to local parsing.\"\"\"\n",
    "    \n",
    "    def __init__(self, use_llamacloud: bool = True):\n",
    "        self.use_llamacloud = use_llamacloud and llama_cloud_key\n",
    "        self.llamaparse = None\n",
    "        \n",
    "        if self.use_llamacloud and LLAMAPARSE_AVAILABLE:\n",
    "            try:\n",
    "                from llama_parse import LlamaParse\n",
    "                self.llamaparse = LlamaParse(\n",
    "                    api_key=llama_cloud_key,\n",
    "                    result_type=\"markdown\",\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"LlamaParse init failed: {e}\")\n",
    "                self.use_llamacloud = False\n",
    "    \n",
    "    def load_document(self, file_path: str) -> list:\n",
    "        \"\"\"Load a document, using LlamaCloud if available.\"\"\"\n",
    "        path = Path(file_path)\n",
    "        \n",
    "        # Try LlamaCloud for PDFs\n",
    "        if path.suffix.lower() == '.pdf' and self.llamaparse:\n",
    "            try:\n",
    "                print(f\"Using LlamaParse for: {path.name}\")\n",
    "                return self.llamaparse.load_data(str(path))\n",
    "            except Exception as e:\n",
    "                print(f\"LlamaParse failed, falling back to local: {e}\")\n",
    "        \n",
    "        # Fallback to local parsing\n",
    "        print(f\"Using local parsing for: {path.name}\")\n",
    "        return self._local_parse(path)\n",
    "    \n",
    "    def _local_parse(self, path: Path) -> list:\n",
    "        \"\"\"Local document parsing fallback.\"\"\"\n",
    "        if path.suffix.lower() == '.txt':\n",
    "            return [Document(text=path.read_text())]\n",
    "        elif path.suffix.lower() == '.pdf':\n",
    "            # Use pypdf or similar\n",
    "            try:\n",
    "                from pypdf import PdfReader\n",
    "                reader = PdfReader(str(path))\n",
    "                text = \"\\n\".join(page.extract_text() for page in reader.pages)\n",
    "                return [Document(text=text)]\n",
    "            except ImportError:\n",
    "                print(\"pypdf not installed for local PDF parsing\")\n",
    "                return []\n",
    "        else:\n",
    "            return [Document(text=path.read_text())]\n",
    "\n",
    "print(\"✓ HybridDocumentLoader defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the hybrid loader\n",
    "loader = HybridDocumentLoader(use_llamacloud=True)\n",
    "\n",
    "print(f\"LlamaCloud enabled: {loader.use_llamacloud}\")\n",
    "print(f\"LlamaParse available: {loader.llamaparse is not None}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary\n",
    "\n",
    "You've learned about LlamaCloud services:\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "| Service | Purpose | Key Feature |\n",
    "|---------|---------|-------------|\n",
    "| **LlamaParse** | Document parsing | Best PDF/table handling |\n",
    "| **LlamaExtract** | Structured extraction | Schema-based extraction |\n",
    "| **Managed Index** | Cloud RAG | Zero infrastructure |\n",
    "\n",
    "### When to Use LlamaCloud\n",
    "\n",
    "1. **Complex documents**: Tables, images, multi-column layouts\n",
    "2. **Production systems**: Need reliability and scale\n",
    "3. **Quick prototypes**: Get started fast\n",
    "4. **Structured extraction**: Need specific data fields\n",
    "\n",
    "### Resources\n",
    "\n",
    "- [LlamaCloud Documentation](https://docs.cloud.llamaindex.ai/)\n",
    "- [LlamaParse Guide](https://docs.cloud.llamaindex.ai/llamaparse/getting_started)\n",
    "- [Pricing](https://cloud.llamaindex.ai/pricing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercises\n",
    "\n",
    "1. **PDF comparison**: Parse the same PDF with LlamaParse and local tools, compare quality\n",
    "\n",
    "2. **Extraction schema**: Design a schema for your use case and test with LlamaExtract\n",
    "\n",
    "3. **Managed index**: Create a managed index and compare query latency with local\n",
    "\n",
    "4. **Cost analysis**: Calculate costs for your expected document volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise space\n",
    "# Experiment with LlamaCloud services here!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
