{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# âš¡ Anthropic SDK - Advanced Level\n",
        "\n",
        "## Advanced Patterns and Tool Use\n",
        "\n",
        "This notebook covers advanced features that enable powerful AI applications.\n",
        "\n",
        "### What You'll Learn:\n",
        "- Tool Use (Function Calling) - Let Claude call your functions\n",
        "- Structured JSON outputs\n",
        "- Prompt caching for efficiency\n",
        "- Async operations for performance\n",
        "- Advanced error handling and retries\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import anthropic\n",
        "import json\n",
        "import asyncio\n",
        "from config import MODEL, ANTHROPIC_API_KEY, validate_api_key, DEFAULT_MAX_TOKENS\n",
        "\n",
        "validate_api_key()\n",
        "client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)\n",
        "\n",
        "print(f\"Model: {MODEL}\")\n",
        "print(\"Ready for advanced concepts!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Tool Use (Function Calling)\n",
        "\n",
        "Tool use allows Claude to call functions you define. This is powerful for:\n",
        "- Retrieving real-time data\n",
        "- Performing calculations\n",
        "- Interacting with external systems\n",
        "- Building AI agents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define tools that Claude can use\n",
        "tools = [\n",
        "    {\n",
        "        \"name\": \"get_weather\",\n",
        "        \"description\": \"Get the current weather for a location. Use this when the user asks about weather.\",\n",
        "        \"input_schema\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"location\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"The city and state/country, e.g., 'San Francisco, CA' or 'London, UK'\"\n",
        "                },\n",
        "                \"unit\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"enum\": [\"celsius\", \"fahrenheit\"],\n",
        "                    \"description\": \"Temperature unit (default: celsius)\"\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"location\"]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"calculate\",\n",
        "        \"description\": \"Perform mathematical calculations. Use this for any math operations.\",\n",
        "        \"input_schema\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"expression\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"The mathematical expression to evaluate, e.g., '2 + 2' or 'sqrt(16)'\"\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"expression\"]\n",
        "        }\n",
        "    }\n",
        "]\n",
        "\n",
        "print(\"Tools defined:\")\n",
        "for tool in tools:\n",
        "    print(f\"  - {tool['name']}: {tool['description'][:50]}...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Implement the actual tool functions\n",
        "import math\n",
        "\n",
        "def get_weather(location, unit=\"celsius\"):\n",
        "    \"\"\"Simulated weather function - in production, call a real API.\"\"\"\n",
        "    # Simulated data\n",
        "    weather_data = {\n",
        "        \"San Francisco, CA\": {\"temp_c\": 18, \"condition\": \"Foggy\"},\n",
        "        \"New York, NY\": {\"temp_c\": 22, \"condition\": \"Sunny\"},\n",
        "        \"London, UK\": {\"temp_c\": 15, \"condition\": \"Cloudy\"},\n",
        "    }\n",
        "    \n",
        "    # Default for unknown locations\n",
        "    data = weather_data.get(location, {\"temp_c\": 20, \"condition\": \"Clear\"})\n",
        "    \n",
        "    temp = data[\"temp_c\"]\n",
        "    if unit == \"fahrenheit\":\n",
        "        temp = (temp * 9/5) + 32\n",
        "        \n",
        "    return {\n",
        "        \"location\": location,\n",
        "        \"temperature\": temp,\n",
        "        \"unit\": unit,\n",
        "        \"condition\": data[\"condition\"]\n",
        "    }\n",
        "\n",
        "def calculate(expression):\n",
        "    \"\"\"Safely evaluate mathematical expressions.\"\"\"\n",
        "    # Create a safe namespace with math functions\n",
        "    safe_dict = {\n",
        "        \"abs\": abs, \"round\": round,\n",
        "        \"sqrt\": math.sqrt, \"pow\": pow,\n",
        "        \"sin\": math.sin, \"cos\": math.cos, \"tan\": math.tan,\n",
        "        \"log\": math.log, \"log10\": math.log10,\n",
        "        \"pi\": math.pi, \"e\": math.e\n",
        "    }\n",
        "    try:\n",
        "        result = eval(expression, {\"__builtins__\": {}}, safe_dict)\n",
        "        return {\"expression\": expression, \"result\": result}\n",
        "    except Exception as e:\n",
        "        return {\"expression\": expression, \"error\": str(e)}\n",
        "\n",
        "# Test the functions\n",
        "print(\"Testing get_weather:\")\n",
        "print(get_weather(\"San Francisco, CA\"))\n",
        "print(\"\\nTesting calculate:\")\n",
        "print(calculate(\"sqrt(16) + 2**3\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make a request with tools\n",
        "response = client.messages.create(\n",
        "    model=MODEL,\n",
        "    max_tokens=1024,\n",
        "    tools=tools,\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": \"What's the weather like in San Francisco?\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(\"Response type:\", response.stop_reason)\n",
        "print(\"\\nContent blocks:\")\n",
        "for block in response.content:\n",
        "    print(f\"  Type: {block.type}\")\n",
        "    if block.type == \"tool_use\":\n",
        "        print(f\"  Tool: {block.name}\")\n",
        "        print(f\"  Input: {block.input}\")\n",
        "        print(f\"  ID: {block.id}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Complete tool use loop - execute tool and return result\n",
        "def process_tool_call(tool_name, tool_input):\n",
        "    \"\"\"Execute a tool and return the result.\"\"\"\n",
        "    if tool_name == \"get_weather\":\n",
        "        return get_weather(**tool_input)\n",
        "    elif tool_name == \"calculate\":\n",
        "        return calculate(**tool_input)\n",
        "    else:\n",
        "        return {\"error\": f\"Unknown tool: {tool_name}\"}\n",
        "\n",
        "def chat_with_tools(user_message, tools):\n",
        "    \"\"\"Complete conversation loop with tool use.\"\"\"\n",
        "    messages = [{\"role\": \"user\", \"content\": user_message}]\n",
        "    \n",
        "    while True:\n",
        "        response = client.messages.create(\n",
        "            model=MODEL,\n",
        "            max_tokens=1024,\n",
        "            tools=tools,\n",
        "            messages=messages\n",
        "        )\n",
        "        \n",
        "        # If Claude wants to use a tool\n",
        "        if response.stop_reason == \"tool_use\":\n",
        "            # Process each tool use in the response\n",
        "            tool_results = []\n",
        "            for block in response.content:\n",
        "                if block.type == \"tool_use\":\n",
        "                    print(f\"ðŸ”§ Calling tool: {block.name}\")\n",
        "                    print(f\"   Input: {block.input}\")\n",
        "                    \n",
        "                    result = process_tool_call(block.name, block.input)\n",
        "                    print(f\"   Result: {result}\\n\")\n",
        "                    \n",
        "                    tool_results.append({\n",
        "                        \"type\": \"tool_result\",\n",
        "                        \"tool_use_id\": block.id,\n",
        "                        \"content\": json.dumps(result)\n",
        "                    })\n",
        "            \n",
        "            # Add assistant response and tool results to messages\n",
        "            messages.append({\"role\": \"assistant\", \"content\": response.content})\n",
        "            messages.append({\"role\": \"user\", \"content\": tool_results})\n",
        "        \n",
        "        else:\n",
        "            # Claude is done - return final response\n",
        "            final_text = \"\"\n",
        "            for block in response.content:\n",
        "                if hasattr(block, \"text\"):\n",
        "                    final_text += block.text\n",
        "            return final_text\n",
        "\n",
        "# Test the complete loop\n",
        "print(\"=\" * 60)\n",
        "result = chat_with_tools(\"What's the weather in London and what's 15 * 7?\", tools)\n",
        "print(\"=\" * 60)\n",
        "print(\"\\nFinal Response:\")\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Structured JSON Output\n",
        "\n",
        "Force Claude to output valid JSON for structured data extraction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Method 1: Using system prompt and prefilled assistant message\n",
        "def extract_json(text, schema_description):\n",
        "    \"\"\"Extract structured JSON from text.\"\"\"\n",
        "    response = client.messages.create(\n",
        "        model=MODEL,\n",
        "        max_tokens=1024,\n",
        "        system=f\"\"\"You are a data extraction assistant. Extract information and return ONLY valid JSON.\n",
        "Schema: {schema_description}\n",
        "Return ONLY the JSON object, no other text.\"\"\",\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": f\"Extract data from: {text}\"},\n",
        "            {\"role\": \"assistant\", \"content\": \"{\"}  # Prefill to force JSON\n",
        "        ]\n",
        "    )\n",
        "    \n",
        "    # Reconstruct the JSON (we prefilled with \"{\")\n",
        "    json_str = \"{\" + response.content[0].text\n",
        "    return json.loads(json_str)\n",
        "\n",
        "# Test extraction\n",
        "text = \"\"\"\n",
        "John Smith is a 35-year-old software engineer from Seattle. \n",
        "He has 10 years of experience and specializes in Python and JavaScript.\n",
        "His email is john.smith@email.com.\n",
        "\"\"\"\n",
        "\n",
        "schema = \"\"\"\n",
        "{\n",
        "    \"name\": \"string\",\n",
        "    \"age\": \"number\",\n",
        "    \"occupation\": \"string\",\n",
        "    \"location\": \"string\",\n",
        "    \"skills\": [\"string\"],\n",
        "    \"email\": \"string\"\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "result = extract_json(text, schema)\n",
        "print(\"Extracted Data:\")\n",
        "print(json.dumps(result, indent=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Method 2: Using tools for guaranteed JSON schema\n",
        "def extract_with_tool(text, tool_schema):\n",
        "    \"\"\"Use tool use to guarantee JSON output matches schema.\"\"\"\n",
        "    extraction_tool = {\n",
        "        \"name\": \"extract_data\",\n",
        "        \"description\": \"Extract and structure data from text\",\n",
        "        \"input_schema\": tool_schema\n",
        "    }\n",
        "    \n",
        "    response = client.messages.create(\n",
        "        model=MODEL,\n",
        "        max_tokens=1024,\n",
        "        tools=[extraction_tool],\n",
        "        tool_choice={\"type\": \"tool\", \"name\": \"extract_data\"},  # Force tool use\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": f\"Extract the following information: {text}\"}\n",
        "        ]\n",
        "    )\n",
        "    \n",
        "    # Get the tool input (which is our structured data)\n",
        "    for block in response.content:\n",
        "        if block.type == \"tool_use\":\n",
        "            return block.input\n",
        "    return None\n",
        "\n",
        "# Define schema as JSON Schema\n",
        "person_schema = {\n",
        "    \"type\": \"object\",\n",
        "    \"properties\": {\n",
        "        \"name\": {\"type\": \"string\", \"description\": \"Full name\"},\n",
        "        \"age\": {\"type\": \"integer\", \"description\": \"Age in years\"},\n",
        "        \"occupation\": {\"type\": \"string\", \"description\": \"Job title\"},\n",
        "        \"skills\": {\n",
        "            \"type\": \"array\",\n",
        "            \"items\": {\"type\": \"string\"},\n",
        "            \"description\": \"List of skills\"\n",
        "        }\n",
        "    },\n",
        "    \"required\": [\"name\", \"age\", \"occupation\"]\n",
        "}\n",
        "\n",
        "result = extract_with_tool(text, person_schema)\n",
        "print(\"Extracted with Tool Schema:\")\n",
        "print(json.dumps(result, indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Prompt Caching\n",
        "\n",
        "Cache long prompts to reduce latency and costs for repeated requests."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prompt caching example\n",
        "# The system prompt or large context can be cached\n",
        "\n",
        "# Create a long context (needs to be at least 1024 tokens for caching)\n",
        "long_context = \"\"\"\n",
        "# Python Programming Guide\n",
        "\n",
        "## Chapter 1: Introduction to Python\n",
        "Python is a high-level, interpreted programming language known for its simplicity and readability.\n",
        "It was created by Guido van Rossum and first released in 1991. Python's design philosophy \n",
        "emphasizes code readability with the use of significant indentation.\n",
        "\n",
        "## Chapter 2: Variables and Data Types\n",
        "Python supports various data types including integers, floats, strings, lists, tuples, \n",
        "dictionaries, and sets. Variables in Python are dynamically typed, meaning you don't need \n",
        "to declare their type explicitly.\n",
        "\n",
        "## Chapter 3: Control Flow\n",
        "Python uses if, elif, and else statements for conditional execution. For loops iterate over \n",
        "sequences, while loops continue until a condition is false. Python also supports break, \n",
        "continue, and pass statements.\n",
        "\n",
        "## Chapter 4: Functions\n",
        "Functions in Python are defined using the def keyword. They can accept positional arguments, \n",
        "keyword arguments, *args for variable positional arguments, and **kwargs for variable \n",
        "keyword arguments. Python supports lambda functions for simple anonymous functions.\n",
        "\n",
        "## Chapter 5: Object-Oriented Programming\n",
        "Python supports object-oriented programming with classes and objects. Classes define \n",
        "blueprints for objects, encapsulating data and behavior. Python supports inheritance, \n",
        "polymorphism, and encapsulation.\n",
        "\n",
        "## Chapter 6: Modules and Packages\n",
        "Python code can be organized into modules (single files) and packages (directories of modules).\n",
        "The import statement allows you to use code from other modules. Python has a rich standard \n",
        "library and thousands of third-party packages available via pip.\n",
        "\n",
        "## Chapter 7: Error Handling\n",
        "Python uses try-except blocks for error handling. You can catch specific exceptions or use \n",
        "a general except clause. The finally block executes regardless of whether an exception occurred.\n",
        "You can also raise custom exceptions.\n",
        "\n",
        "## Chapter 8: File I/O\n",
        "Python provides built-in functions for reading and writing files. The open() function returns \n",
        "a file object, and you can use context managers (with statement) to ensure proper file handling.\n",
        "Python supports text and binary file modes.\n",
        "\"\"\" * 3  # Repeat to ensure enough tokens\n",
        "\n",
        "# First request - will cache the context\n",
        "response1 = client.messages.create(\n",
        "    model=MODEL,\n",
        "    max_tokens=200,\n",
        "    system=[\n",
        "        {\n",
        "            \"type\": \"text\",\n",
        "            \"text\": long_context,\n",
        "            \"cache_control\": {\"type\": \"ephemeral\"}  # Mark for caching\n",
        "        }\n",
        "    ],\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": \"What is Python according to Chapter 1?\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(\"First Request (caching the context):\")\n",
        "print(f\"Input tokens: {response1.usage.input_tokens}\")\n",
        "if hasattr(response1.usage, 'cache_creation_input_tokens'):\n",
        "    print(f\"Cache creation tokens: {response1.usage.cache_creation_input_tokens}\")\n",
        "if hasattr(response1.usage, 'cache_read_input_tokens'):\n",
        "    print(f\"Cache read tokens: {response1.usage.cache_read_input_tokens}\")\n",
        "print(f\"\\nResponse: {response1.content[0].text[:200]}...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Second request - should use cached context\n",
        "response2 = client.messages.create(\n",
        "    model=MODEL,\n",
        "    max_tokens=200,\n",
        "    system=[\n",
        "        {\n",
        "            \"type\": \"text\",\n",
        "            \"text\": long_context,\n",
        "            \"cache_control\": {\"type\": \"ephemeral\"}\n",
        "        }\n",
        "    ],\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": \"What does Chapter 5 cover?\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(\"Second Request (using cached context):\")\n",
        "print(f\"Input tokens: {response2.usage.input_tokens}\")\n",
        "if hasattr(response2.usage, 'cache_creation_input_tokens'):\n",
        "    print(f\"Cache creation tokens: {response2.usage.cache_creation_input_tokens}\")\n",
        "if hasattr(response2.usage, 'cache_read_input_tokens'):\n",
        "    print(f\"Cache read tokens: {response2.usage.cache_read_input_tokens}\")\n",
        "print(f\"\\nResponse: {response2.content[0].text[:200]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Async Operations\n",
        "\n",
        "Use async for better performance when making multiple concurrent requests."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "# Create async client\n",
        "async_client = anthropic.AsyncAnthropic(api_key=ANTHROPIC_API_KEY)\n",
        "\n",
        "async def async_chat(message):\n",
        "    \"\"\"Make an async API call.\"\"\"\n",
        "    response = await async_client.messages.create(\n",
        "        model=MODEL,\n",
        "        max_tokens=100,\n",
        "        messages=[{\"role\": \"user\", \"content\": message}]\n",
        "    )\n",
        "    return response.content[0].text\n",
        "\n",
        "async def run_parallel_requests():\n",
        "    \"\"\"Run multiple requests in parallel.\"\"\"\n",
        "    questions = [\n",
        "        \"What is 2+2?\",\n",
        "        \"Name a color.\",\n",
        "        \"What is Python?\",\n",
        "        \"Name a planet.\",\n",
        "        \"What is AI?\"\n",
        "    ]\n",
        "    \n",
        "    print(\"Running 5 requests in parallel...\")\n",
        "    start = time.time()\n",
        "    \n",
        "    # Run all requests concurrently\n",
        "    tasks = [async_chat(q) for q in questions]\n",
        "    results = await asyncio.gather(*tasks)\n",
        "    \n",
        "    elapsed = time.time() - start\n",
        "    print(f\"Completed in {elapsed:.2f} seconds\\n\")\n",
        "    \n",
        "    for q, r in zip(questions, results):\n",
        "        print(f\"Q: {q}\")\n",
        "        print(f\"A: {r[:100]}...\")\n",
        "        print()\n",
        "    \n",
        "    return results\n",
        "\n",
        "# Run the async function\n",
        "# In Jupyter, we can use await directly\n",
        "results = await run_parallel_requests()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare with sequential requests\n",
        "async def run_sequential_requests():\n",
        "    \"\"\"Run requests sequentially for comparison.\"\"\"\n",
        "    questions = [\n",
        "        \"What is 2+2?\",\n",
        "        \"Name a color.\",\n",
        "        \"What is Python?\",\n",
        "        \"Name a planet.\",\n",
        "        \"What is AI?\"\n",
        "    ]\n",
        "    \n",
        "    print(\"Running 5 requests sequentially...\")\n",
        "    start = time.time()\n",
        "    \n",
        "    results = []\n",
        "    for q in questions:\n",
        "        result = await async_chat(q)\n",
        "        results.append(result)\n",
        "    \n",
        "    elapsed = time.time() - start\n",
        "    print(f\"Completed in {elapsed:.2f} seconds\")\n",
        "    print(\"(Compare with parallel time above)\")\n",
        "    \n",
        "    return results\n",
        "\n",
        "sequential_results = await run_sequential_requests()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Advanced Error Handling with Retries\n",
        "\n",
        "Implement robust error handling with exponential backoff."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "class RobustAnthropicClient:\n",
        "    \"\"\"A wrapper with automatic retries and error handling.\"\"\"\n",
        "    \n",
        "    def __init__(self, client, max_retries=3, base_delay=1.0):\n",
        "        self.client = client\n",
        "        self.max_retries = max_retries\n",
        "        self.base_delay = base_delay\n",
        "    \n",
        "    def _calculate_delay(self, attempt):\n",
        "        \"\"\"Calculate delay with exponential backoff and jitter.\"\"\"\n",
        "        delay = self.base_delay * (2 ** attempt)\n",
        "        jitter = random.uniform(0, 0.1 * delay)\n",
        "        return delay + jitter\n",
        "    \n",
        "    def create_message(self, **kwargs):\n",
        "        \"\"\"Create a message with automatic retries.\"\"\"\n",
        "        last_exception = None\n",
        "        \n",
        "        for attempt in range(self.max_retries):\n",
        "            try:\n",
        "                return self.client.messages.create(**kwargs)\n",
        "            \n",
        "            except anthropic.RateLimitError as e:\n",
        "                last_exception = e\n",
        "                delay = self._calculate_delay(attempt)\n",
        "                print(f\"Rate limited. Retrying in {delay:.2f}s (attempt {attempt + 1}/{self.max_retries})\")\n",
        "                time.sleep(delay)\n",
        "            \n",
        "            except anthropic.APIConnectionError as e:\n",
        "                last_exception = e\n",
        "                delay = self._calculate_delay(attempt)\n",
        "                print(f\"Connection error. Retrying in {delay:.2f}s (attempt {attempt + 1}/{self.max_retries})\")\n",
        "                time.sleep(delay)\n",
        "            \n",
        "            except anthropic.InternalServerError as e:\n",
        "                last_exception = e\n",
        "                delay = self._calculate_delay(attempt)\n",
        "                print(f\"Server error. Retrying in {delay:.2f}s (attempt {attempt + 1}/{self.max_retries})\")\n",
        "                time.sleep(delay)\n",
        "            \n",
        "            except anthropic.APIStatusError as e:\n",
        "                # Don't retry client errors (4xx)\n",
        "                if 400 <= e.status_code < 500:\n",
        "                    raise\n",
        "                last_exception = e\n",
        "                delay = self._calculate_delay(attempt)\n",
        "                print(f\"API error {e.status_code}. Retrying in {delay:.2f}s\")\n",
        "                time.sleep(delay)\n",
        "        \n",
        "        # All retries exhausted\n",
        "        raise last_exception\n",
        "\n",
        "# Create robust client\n",
        "robust_client = RobustAnthropicClient(client)\n",
        "\n",
        "# Test it\n",
        "response = robust_client.create_message(\n",
        "    model=MODEL,\n",
        "    max_tokens=100,\n",
        "    messages=[{\"role\": \"user\", \"content\": \"Hello!\"}]\n",
        ")\n",
        "print(\"Response:\", response.content[0].text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Practice Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
