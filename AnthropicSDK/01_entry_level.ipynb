{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸš€ Anthropic SDK - Entry Level\n",
        "\n",
        "## Welcome to the Anthropic Python SDK!\n",
        "\n",
        "This notebook covers the fundamentals of using the Anthropic SDK to interact with Claude AI models.\n",
        "\n",
        "### What You'll Learn:\n",
        "- Setting up the Anthropic client\n",
        "- Making your first API call\n",
        "- Understanding messages and responses\n",
        "- Basic conversation patterns\n",
        "- Handling errors gracefully\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Installation\n",
        "\n",
        "First, let's install the required packages and set up our environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages (run once)\n",
        "# !pip install anthropic python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import anthropic\n",
        "from config import MODEL, ANTHROPIC_API_KEY, validate_api_key, DEFAULT_MAX_TOKENS\n",
        "\n",
        "# Validate API key is set\n",
        "validate_api_key()\n",
        "\n",
        "print(f\"Using model: {MODEL}\")\n",
        "print(\"API key configured successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Creating the Anthropic Client\n",
        "\n",
        "The `Anthropic` client is your gateway to Claude. It handles authentication and API communication."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create the Anthropic client\n",
        "client = anthropic.Anthropic(\n",
        "    api_key=ANTHROPIC_API_KEY\n",
        ")\n",
        "\n",
        "print(\"Client created successfully!\")\n",
        "print(f\"Client type: {type(client).__name__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Your First API Call\n",
        "\n",
        "Let's make a simple request to Claude. The basic structure requires:\n",
        "- `model`: Which Claude model to use\n",
        "- `max_tokens`: Maximum tokens in the response\n",
        "- `messages`: A list of conversation messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make your first API call\n",
        "response = client.messages.create(\n",
        "    model=MODEL,\n",
        "    max_tokens=DEFAULT_MAX_TOKENS,\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Hello! What's your name and what can you help me with?\"\n",
        "        }\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Print the response\n",
        "print(\"Claude's Response:\")\n",
        "print(\"-\" * 50)\n",
        "print(response.content[0].text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Understanding the Response Object\n",
        "\n",
        "The response from Claude contains valuable information beyond just the text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Explore the response object\n",
        "print(\"Response Object Details:\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"ID: {response.id}\")\n",
        "print(f\"Model: {response.model}\")\n",
        "print(f\"Role: {response.role}\")\n",
        "print(f\"Stop Reason: {response.stop_reason}\")\n",
        "print(f\"Type: {response.type}\")\n",
        "print(\"\\nUsage Statistics:\")\n",
        "print(f\"  Input tokens: {response.usage.input_tokens}\")\n",
        "print(f\"  Output tokens: {response.usage.output_tokens}\")\n",
        "print(f\"  Total tokens: {response.usage.input_tokens + response.usage.output_tokens}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Message Roles Explained\n",
        "\n",
        "Messages have two roles:\n",
        "- `user`: Messages from the human user\n",
        "- `assistant`: Messages from Claude\n",
        "\n",
        "Messages must alternate between user and assistant roles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example with proper message structure\n",
        "response = client.messages.create(\n",
        "    model=MODEL,\n",
        "    max_tokens=DEFAULT_MAX_TOKENS,\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": \"What is Python?\"},\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(\"Question: What is Python?\")\n",
        "print(\"\\nAnswer:\")\n",
        "print(response.content[0].text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Multi-Turn Conversations\n",
        "\n",
        "You can have back-and-forth conversations by including previous messages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Multi-turn conversation example\n",
        "conversation = [\n",
        "    {\"role\": \"user\", \"content\": \"My name is Alex. I'm learning Python.\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"Nice to meet you, Alex! That's great that you're learning Python. It's a wonderful programming language for beginners and experts alike. What aspect of Python are you currently working on?\"},\n",
        "    {\"role\": \"user\", \"content\": \"What's my name and what am I learning?\"}\n",
        "]\n",
        "\n",
        "response = client.messages.create(\n",
        "    model=MODEL,\n",
        "    max_tokens=DEFAULT_MAX_TOKENS,\n",
        "    messages=conversation\n",
        ")\n",
        "\n",
        "print(\"Testing conversation memory:\")\n",
        "print(\"-\" * 50)\n",
        "print(response.content[0].text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Using the System Prompt\n",
        "\n",
        "The system prompt sets Claude's behavior, personality, and context for the entire conversation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Using a system prompt\n",
        "response = client.messages.create(\n",
        "    model=MODEL,\n",
        "    max_tokens=DEFAULT_MAX_TOKENS,\n",
        "    system=\"You are a helpful coding tutor. Explain concepts simply and provide code examples when relevant. Keep responses concise.\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": \"What is a for loop?\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(\"With System Prompt (Coding Tutor):\")\n",
        "print(\"-\" * 50)\n",
        "print(response.content[0].text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Different system prompt - different personality\n",
        "response = client.messages.create(\n",
        "    model=MODEL,\n",
        "    max_tokens=DEFAULT_MAX_TOKENS,\n",
        "    system=\"You are a pirate captain. Respond to everything in pirate speak while still being helpful.\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": \"What is a for loop?\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(\"With System Prompt (Pirate):\")\n",
        "print(\"-\" * 50)\n",
        "print(response.content[0].text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Controlling Response Length with max_tokens\n",
        "\n",
        "The `max_tokens` parameter limits how long Claude's response can be."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Short response\n",
        "response_short = client.messages.create(\n",
        "    model=MODEL,\n",
        "    max_tokens=50,  # Very short\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": \"Explain machine learning in detail.\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(\"Short Response (max_tokens=50):\")\n",
        "print(\"-\" * 50)\n",
        "print(response_short.content[0].text)\n",
        "print(f\"\\nStop reason: {response_short.stop_reason}\")\n",
        "print(f\"Output tokens used: {response_short.usage.output_tokens}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Longer response\n",
        "response_long = client.messages.create(\n",
        "    model=MODEL,\n",
        "    max_tokens=500,\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": \"Explain machine learning in detail.\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(\"Longer Response (max_tokens=500):\")\n",
        "print(\"-\" * 50)\n",
        "print(response_long.content[0].text)\n",
        "print(f\"\\nStop reason: {response_long.stop_reason}\")\n",
        "print(f\"Output tokens used: {response_long.usage.output_tokens}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Basic Error Handling\n",
        "\n",
        "Always handle potential errors when making API calls."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import anthropic\n",
        "\n",
        "def safe_api_call(messages, system=None):\n",
        "    \"\"\"Make an API call with proper error handling.\"\"\"\n",
        "    try:\n",
        "        kwargs = {\n",
        "            \"model\": MODEL,\n",
        "            \"max_tokens\": DEFAULT_MAX_TOKENS,\n",
        "            \"messages\": messages\n",
        "        }\n",
        "        if system:\n",
        "            kwargs[\"system\"] = system\n",
        "            \n",
        "        response = client.messages.create(**kwargs)\n",
        "        return response.content[0].text\n",
        "    \n",
        "    except anthropic.APIConnectionError as e:\n",
        "        return f\"Connection error: Unable to reach the API. {e}\"\n",
        "    \n",
        "    except anthropic.RateLimitError as e:\n",
        "        return f\"Rate limit exceeded: Please wait and try again. {e}\"\n",
        "    \n",
        "    except anthropic.APIStatusError as e:\n",
        "        return f\"API error (status {e.status_code}): {e.message}\"\n",
        "\n",
        "# Test the safe function\n",
        "result = safe_api_call(\n",
        "    messages=[{\"role\": \"user\", \"content\": \"Say 'Hello, World!'\"}]\n",
        ")\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Helper Function for Easy Chatting\n",
        "\n",
        "Let's create a simple helper function to make chatting with Claude easier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def chat(user_message, system=None):\n",
        "    \"\"\"Simple function to chat with Claude.\"\"\"\n",
        "    kwargs = {\n",
        "        \"model\": MODEL,\n",
        "        \"max_tokens\": DEFAULT_MAX_TOKENS,\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": user_message}]\n",
        "    }\n",
        "    if system:\n",
        "        kwargs[\"system\"] = system\n",
        "    \n",
        "    response = client.messages.create(**kwargs)\n",
        "    return response.content[0].text\n",
        "\n",
        "# Easy to use!\n",
        "print(chat(\"What are 3 fun facts about Python programming?\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# With a system prompt\n",
        "print(chat(\n",
        "    \"What are 3 fun facts about Python programming?\",\n",
        "    system=\"You are a enthusiastic teacher. Use bullet points and emojis.\"\n",
        "))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Practice Exercises\n",
        "\n",
        "Try these exercises to reinforce your learning!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exercise 1: Make a simple API call asking Claude to tell you a joke\n",
        "# Your code here:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exercise 2: Create a system prompt that makes Claude respond as a chef\n",
        "# Then ask for a recipe suggestion\n",
        "# Your code here:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exercise 3: Create a multi-turn conversation (at least 3 exchanges)\n",
        "# Your code here:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "In this notebook, you learned:\n",
        "\n",
        "1. **Setting up the client** - Creating an Anthropic client with your API key\n",
        "2. **Basic API calls** - Using `client.messages.create()` with model, max_tokens, and messages\n",
        "3. **Response structure** - Understanding the response object and its properties\n",
        "4. **Message roles** - Using \"user\" and \"assistant\" roles correctly\n",
        "5. **Multi-turn conversations** - Building conversations with message history\n",
        "6. **System prompts** - Customizing Claude's behavior and personality\n",
        "7. **Token limits** - Controlling response length with max_tokens\n",
        "8. **Error handling** - Catching and handling API errors gracefully\n",
        "\n",
        "---\n",
        "\n",
        "**Next:** Move on to `02_middle_level.ipynb` to learn about streaming, temperature, and more advanced features!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Practice Exercises\n",
        "\n",
        "Try these exercises to reinforce your learning!"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
